---
title             : "A universal of human social cognition: Children from 17 communities process gaze in similar ways"
shorttitle        : "Gaze following across 17 communities"

author: 
  - name          : "Manuel Bohn"
    affiliation   : "1,2,*"
    corresponding : yes    # Define only one corresponding author
    address       : "Universitätsallee 1, 21335 Lüneburg, Germany"
    email         : "manuel.bohn@leuphana.de"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Methodology"
      - "Formal Analysis"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Julia Christin Prein"
    affiliation   : "1,2,*"
    role:
      - "Conceptualization"
      - "Methodology"
      - "Software"
      - "Investigation"
      - "Writing - Review & Editing"
  - name          : "Agnes Ayikoru"
    affiliation   : "3"
    role:
      - "Investigation"
  - name          : "Florian M. Bednarski"
    affiliation   : "4"
    role:
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Ardain Dzabatou"
    affiliation   : "5"
    role:
      - "Investigation"
  - name          : "Michael C. Frank"
    affiliation   : "6"
    role:
      - "Investigation"
      - "Writing - Review & Editing"
  - name          : "Annette M. E. Henderson"
    affiliation   : "4"
    role:
      - "Investigation"
      - "Writing - Review & Editing"      
  - name          : "Joan Isabella"
    affiliation   : "3"
    role:
     - "Investigation" 
  - name          : "Josefine Kalbitz"
    affiliation   : "2"
    role:
      - "Investigation"
      - "Writing - Review & Editing"
  - name          : "Patricia Kanngiesser"
    affiliation   : "7"
    role:
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Dilara Keşşafoğlu"
    affiliation   : "8"
    role:
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Bahar Köymen"
    affiliation   : "9"
    role:
      - "Investigation"
      - "Writing - Review & Editing"  
  - name          : "Maira V. Manrique-Hernandez"
    affiliation   : "2"
    role:
      - "Investigation"
  - name          : "Shirley Magazi"
    affiliation   : "10"
    role:
      - "Investigation"
  - name          : "Lizbeth Mújica-Manrique"
    affiliation   : "2"
    role:
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Julia Ohlendorf"
    affiliation   : "2"
    role:
      - "Investigation"
  - name          : "Damilola Olaoba"
    affiliation   : "2"
    role:
     - "Investigation"
  - name          : "Wesley R. Pieters"
    affiliation   : "10"
    role:
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Sarah Pope-Caldwell"
    affiliation   : "2"
    role:
     - "Investigation"    
  - name          : "Katie Slocombe"
    affiliation   : "11"
    role:
     - "Investigation"
     - "Writing - Review & Editing"
  - name          : "Robert Z. Sparks"
    affiliation   : "6"
    role:
      - "Investigation"
  - name          : "Jahnavi Sunderarajan"
    affiliation   : "2"
    role:
      - "Investigation"
  - name          : "Wilson Vieira"
    affiliation   : "2"
    role:
     - "Investigation"
  - name          : "Zhen Zhang"
    affiliation   : "12"
    role:
      - "Investigation"
      - "Writing - Review & Editing"   
  - name          : "Yufei Zong"
    affiliation   : "12"
    role:
      - "Investigation"
  - name          : "Roman Stengelin"
    affiliation   : "2,10,+"
    role:
      - "Conceptualization"
      - "Methodology"
      - "Investigation"
      - "Writing - Review & Editing" 
  - name          : "Daniel B. M. Haun"
    affiliation   : "2,+"
    role:
      - "Conceptualization"
      - "Funding acquisition"
      - "Writing - Review & Editing"
      


affiliation:
  - id            : "1"
    institution   : "Institute of Psychology in Education, Leuphana University Lüneburg"
  - id            : "2"
    institution   : "Department of Comparative Cultural Psychology, Max Planck Institute for Evolutionary Anthropology"
  - id            : "3"
    institution   : "Budongo Conservation Field Station"
  - id            : "4"
    institution   : "School of Psychology, University of Auckland"
  - id            : "5"
    institution   : "Université Marien Ngouabi"
  - id            : "6"
    institution   : "Department of Psychology, Stanford University"
  - id            : "7"
    institution   : "School of Psychology, University of Plymouth"
  - id            : "8"
    institution   : "Department of Psychology, Koç University"
  - id            : "9"
    institution   : "Division of Psychology, Communication, and Human Neuroscience, University of Manchester"   
  - id            : "10"
    institution   : "Department of Psychology and Social Work, University of Namibia"
  - id            : "11"
    institution   : "Department of Psychology, University of York"
  - id            : "12"
    institution   : "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences"
  - id            : "*"
    institution   : "joint first author"
  - id            : "+"
    institution   : "joint last author"


  
  

authornote: |
   The authors would like to thank Luke Maurits for statistical advice. Manuel Bohn was supported by a Jacobs Foundation Research Fellowship (2022-1484-00). We are grateful to thank all children and caregivers for participating in the study. We thank the Max Planck Society for the Advancement of Science.

abstract: |
  Theoretical accounts assume that key features of human social cognition are universal. The present study presents a comprehensive cross-cultural study (17 cultural communities, five continents, N = 1377, 709 female,  mean = 5.50 years ) on gaze following in early childhood. To test for universality, a cognitive processing signature was derived from a computational model that treats gaze following as social vector estimation. Results showed substantial variation between communities and individuals. Importantly, the processing signature was found in all communities. Individual differences in performance were related to individual-level measures of familiarity with the data collection device but not opportunities for social interaction. These results provide strong evidence for a universal cognitive process that can be inferred despite cultural variation in overt behavior.

  
bibliography      : "library.bib"

floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            :
  papaja::apa6_docx:
    latex_engine: xelatex
    keep_tex: true
editor_options    : 
  markdown: 
    wrap: sentence
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{unicode-math}
  - \usepackage{setspace}
  - \usepackage{libertine}
  - \captionsetup[figure]{font={stretch=1}}
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother
---

```{r setup, include = FALSE}
library("papaja")
library(tidyverse)
library(knitr)
library(kableExtra)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, message = F, warning = F)
options(knitr.kable.NA = '')
```

```{r data}
data <- read_csv("../data/gafo-cc-clean-data.csv")%>%
  mutate(continent = ifelse(
    community %in% c("leipzig", "plymouth"), "Europe", 
    ifelse(
      community %in% c("akure", "hai||om", "khwe", "chimfunshi", "bandongo", "bayaka", "windhoek", "uganda"), "Africa",
      ifelse(community %in% c("stanford", "mexico", "buenos_aires"), "Americas",
             ifelse(community %in% c("india", "beijing", "turkey"), "Asia", "Oceania"))
    )
  ))%>%
  mutate(continent = factor(continent, levels = c("Americas", "Africa", "Europe", "Asia", "Oceania"), ordered = T))%>%
  mutate(community = recode(community,
                            akure = "Akure (Nigeria)",
                            leipzig = "Leipzig (Germany)",
                            `hai||om` = "Hai||om (Namibia)",
                            khwe = "Khwe (Namibia)",
                            windhoek = "Windhoek (Namibia)",
                            stanford = "Stanford (USA)",
                            chimfunshi = "Chimfunshi (Zambia)",
                            mexico = "Ocuilan (México)",
                            plymouth = "Plymouth (UK)",
                            beijing = "Beijing (China)", 
                            india = "Pune (India)",
                            buenos_aires = "Buenos Aires (Argentina)",
                            auckland = "Auckland (New Zealand)",
                            turkey = "Malatya (Türkiye)",
                            bandongo = "Bandongo (Rep. Congo)",
                            bayaka = "BaYaka (Rep. Congo)", 
                            uganda = "Nyabyeya (Uganda)"))

```

# Introduction 

Human socio-cognitive skills enable unique forms of communication and cooperation that provide a bedrock for cumulative culture and the formation of complex societies [@laland2021understanding; @wellman2014making; @henrich2016secret; @tomasello2003makes; @legare2019development; @heyes2018cognitive]. Eye gaze is essential for many social reasoning processes, making the eyes the proverbial ''window to the mind'' [@shepherd2010following; @doherty2006development; @emery2000eyes; @frischen2007gaze]. Others’ eye gaze is used to infer their focus of visual attention, which is a critical aspect of coordinated activities, including communication and cooperation [@tomasello2007reliance; @scaife1975capacity; @langton2000eyes; @rossano2012gaze; @richardson2005looking; @sebanz2006joint]. During ontogeny, gaze following is an important aspect of many critical learning objectives that enable children to become functioning members of the society they grow up in, including language, social learning and cooperation [@brownell2011early; @moore2008development; @brooks2005development; @carpenter1998social; @mundy2007attention; @stephenson2021gaze]. Because of the central role gaze following plays during human ontogeny, it has been widely argued that gaze following has been a target of natural selection [@tomasello2007reliance; @kano2023evolution; @emery2000eyes; @clark2023white]. This implies that the process by which humans use gaze direction to infer the focus of attention is universal. In this paper, we report a comprehensive cross-cultural study on the ontogeny of gaze following in which we shed light on the universal aspects of gaze following as well as sources of variation and their origins.

## Ontogeny of gaze following

The ability to follow gaze emerges early in development [@tang2023slow; @gredeback2010development; @byers2021development; @del2019developmental]. The earliest signs of gaze following have been found in infants as young as four months [@astor2021gaze; @d1997demonstration]. Throughout the first two years of life, children refine their abilities: they begin to interpret gaze in mentalistic terms [@butterworth1991minds; @deak2000effects], for example, they follow gaze to locations outside their own visual field by moving around barriers [@moll200412]. Initially, children rely more on head direction than actual gaze direction [@michel2021effects]. When head and gaze direction diverge, children often fail to accurately locate the agent's focus of attention up until 19 months of age [@lempers1979young]. 

From an evolutionary perspective, while many species are able to follow gaze based on head directions, uniquely human forms of joint action and communication require a more precise localization of other's attention and thus critically rely on gaze direction inferred from eye movements [@emery2000eyes; @hessels2020does]. In a recent study, @prein2024variation studied the development of gaze following based on eye movements from three years up until old age. They found particularly steep developmental improvements in the preschool years resulting in a relatively stable level of accuracy from ten years onward and a slight decrease starting around age 40. 

The studies reported thus far, relied on data collected in western affluent communitites. Such communitites represent only a minority of the worlds population and are thus insufficient to make claims about universal aspects of human cognition [@nielsen2017persistent; @norenzayan2005psychological; @amir2020cross; @barrett2020towards]. Three studies with infants and children from traditionally underrepresented parts of the world (Bhutan, India, Peru, Vanuatu) find that even though children start gaze following (gaze and head direction combined) at similar ages, the rates of gaze following differ between cultural communitites [@hernik2019infant; @astor2022maternal; @callaghan2011early]. 

Rates and accuracy of gaze following do not just differ between cultural communitites; there is also substantial variation within communitites. In fact, the pivotal role of gaze following in many uniquely human activities has been studied by relating individual differences in gaze following to other phenomena -- both cross-sectionally and longitudinally [@carpenter1998social; @brooks2015connecting]. For example, gaze following at 10 months predicts language scores at 18 months of age [@brooks2005development; @macdonald2013eye]. Furthermore, difficulties with gaze following have been linked to developmental disorders, including Autism [@itier2009neural; @thorup2016altered] and -- at least in some cultural contexts -- to maternal postpartum depression [@astor2022maternal]. Individual differences are also key to explaining the driving forces behind the development of gaze following. For example, it has been found that early attachment quality or the use of gaze in communicative interactions predict later rates of gaze following [@astor2020social; @movellan2002development; @senju2015early].

## Cognitive universals and sources of variation

The existence of variation in gaze following both within and between cultural communitites raises the question of how to square these findings with the suggestion that gaze following is a fundamental building block of human social cognition and interaction and that eye movements are processed the same way in humans all over the world. Looking at other aspects of social cognition, one could easily make the argument that variation is the norm rather than the exception [see e.g., @dixson2018scaling; @miller2018contributions; @wellman2014making; @mayer2013synchrony;  @taumoepeau2019cross]. As a first step, answering this question requires data from many different cultural communitites. In a second step, however, we need a way of detecting universal processes in such data. The traditional approach is to compare some sort of aggregate measure (mean level of performance, average age of onset) across cultural communitites. Absolute differences between communities are interpreted as a signal of different underlying cognitive processes while no differences are taken to support the existence of a psychological universal [@house2020universal; @van2018development; @blake2015ontogeny; @kanngiesser2022children]. Such an approach, however, neglects the existence of within-cultural variation altogether [see also @gurven2018broadening].

In the present study, we want to take a different approach for which we assume that universal processes and variation can co-exist [@kline2018variation; @greenfield2003cultural; @jensen2012bridging]. Instead of starting with the outcome (performance in the task), we start with the process that generates the outcome. By defining this process, we make a proposal for the universal aspects of the process. At the same time, we define variable aspects that generate individual differences. This allows us to define signatures that the process leaves behind that can be detected independent of absolute levels of performance. 

The computational model proposed by @prein2024variation can be used to derive such predictions for gaze following. They formalized the widely-held view that gaze following involves estimating some sort of line-of-sight vector emanating from the eye center through the pupil [@todorovic2006geometrical; @yaniv1990heuristics; @butterworth1991minds]. The key innovation of the model is that it explains how individuals may use the same process but still differ in their measured abilities. The process always involves estimating a vector but also involves a degree of uncertainty because the eye center is not directly observable. Individuals are assumed to differ in their level of uncertainty with which they estimate the vector which causes differences in their observable behavior. Importantly, the general vector estimation process leaves a key signature in the data that is detectable independent of the absolute level of performance. In the present study, we therefore focus on this signature instead of absolute levels of performance when evaluating the claim whether there is evidence for a universal cognitive process underlying gaze following. 

## The current study

The present study had three goals. First, to collect a comprehensive data set and study the ontogeny of gaze following beyond infancy across cultures. To make this possible, we used a semi-standardized task that required minimal assistance from an experimenter and no behavioral coding [TANGO-CC; @prein2024measuring]. The task is an animated picture book presented on a tablet screen. Children watched a balloon disappear behind a hedge. An agent followed the trajectory of the balloon with their eyes (Figure \@ref(fig:fig1)B). The key dependent variable was (im)precision, that is, the deviation between where the agent looked (where the balloon was) and the child’s response. The task's flexible implementation as a browser-based web-app allowed us to quickly tailor its visual and audio content to each cultural community (visuals and audio). Adaptations were made by researchers or research assistants from the respective community. The task has been psychometrically evaluated and has shown to yield reliable individual-level measurements across communities and ages [@prein2024tango; @prein2024measuring]. 

We collected data in 17 different communities across 14 countries and five continents  (see Figure \@ref(fig:fig1)A). Communities covered a broad spectrum of geographical locations, social and political systems, languages, and subsistence styles. This diversity allowed us to overcome a common pitfall of cross-cultural studies that compare urban communities from the Global North to rural communities from the Global South [@barrett2020towards]. We aimed for large sample sizes within each community (n = 20 per year) to contrast within- and between cultural variation. Our expectation regarding the first goal was to see substantial variation across cultures but even more variation between individuals. In all communities, we expected performance to improve with age.

The second goal was to look for signatures in the data of the universal gaze following process specified by the model of @prein2024variation. In the task, the hidden object lands on a horizontal plane at the lower end of the screen. The agent is located in the upper center of the screen (see Figure \@ref(fig:fig1)B). The model predicts trials in which the object is hidden further away from the center to be more difficult, resulting in higher imprecision. The signature is thus a u-shaped relation between object location and imprecision (Figure \@ref(fig:fig12)). 

Finally, we sought to explain individual differences in gaze following precision by linking them to methodological aspects of the study as well as aggregate measures of children's everyday social experience. Experience with tablets and touch screens co-varied with community and we expected children more familiar with this medium to perform better in any tablet-based task. Previous work suggested that gaze following is refined in social interaction [@movellan2002development; @senju2015early]. To approximate social interaction, we asked parents to fill out a questionnaire about household size and composition. We acknowledge that this measure approximates opportunities for social interaction in a rather coarse way but we nevertheless expected children living in larger households and with more siblings (relative to their community) to be more accurate when following gaze. 

```{r fig1, include = T, fig.align = "center", fig.cap = "(A) Data collection sites. Points show the approximate geographical location of the data collection sites, coloring shows the sample sizes. (B) Screenshots from the task. The lower scene depicts the choice phase in a test trial. Participants had to use the gaze of the agent to locate the balloon and touch the location on the hedge where they thought the balloon was. Agents, audio recordings and backgrounds were adapted to each community. (C) Drawings used as agents across communities. Adaptations were made researchers or research assisstants from the respective community.", out.width="100%"}
knitr::include_graphics("../figures/fig1_2.png")
``` 

```{r tab1, include = T}
tba1 <- data %>%
  separate(community, into = c("community", "country"), sep = " \\(")%>%
  mutate(country = str_remove(country, "\\("),
         country = str_remove(country, "\\)"))%>%
  distinct(subjid, .keep_all = T)%>%
  group_by(community, country, continent)%>%
  summarise(N = n_distinct(subjid), 
            m = sum(sex == "m", na.rm = T), 
            mean_age = mean(ageinyears),
            min_age = min(ageinyears), 
            max_age = max(ageinyears), 
            touchscreen = mean(touchscreen, na.rm = T))%>%
  mutate_if(is.numeric, format, digits = 2, nsmall = 2)%>%
  mutate(age = paste0(mean_age, " (", min_age, " - ", max_age, ")"))%>%
  mutate(N = paste0(N, " (", m,")"))%>%
  select(-c(mean_age, min_age, max_age))%>%
  arrange(continent, country)%>%
  group_by(continent) %>%
  mutate(continent = as.character(continent),
         continent = replace(continent, duplicated(continent), " ")) %>%
  ungroup() %>%
  mutate(country = replace(country, duplicated(country), " "))%>%
  mutate(language = c("Spanish (Rioplatense)", "Spanish (Mexican)", "English (American)", "Hai||om", "Khwedam", "English (Nigerian)2", "English (Nigerian)", "Yaka", "Lingala", "Kiswahili", "Bemba", "German", "English (British)", "Mandarin", "English (Indian) / Marathi", "Turkish", "English (New Zealand)"))%>%
  select(continent, country, community, N, age, language, touchscreen)

apa_table(tba1,
          col.names = linebreak(c("Continent", "Country", "Community", "N (male)", "Age (range)", "Language", "Touchscreen exposure1")),
          caption = "Participant demographics.",
          #align = paste0("m{", 1/(ncol(tba1) + 1), "\\linewidth}"),
          longtable = TRUE,
          note = "1 Proportion of participants who have access to touchscreens according to parental questionnaire. 2 Local collaborators and piloting suggested that Nigerian English is suitable for Windhoek as well.",
          escape=TRUE)
```

```{r}
post_agg <- readRDS("../saves/post_agg.rds")
post_fix <- readRDS("../saves/cult_age_fix.rds")

```

# Methods

## Preregistration

The study design, the sampling strategy and the general analytic strategy were preregistered prior to data collection (https://osf.io/tdsvc). The final sample size was not preregistered because we did not know how many communities would participate when the study began. Instead, we stated the age range we intended to study in each community (3.0 to 5.9 years of age) along and that we planned to test 20 children per year bin. We achieved this goal for most ages in most communities, but not for all (see Supplementary Table 1). For some communities, we also included older and younger children. The analysis reported here deviated from the preregistration in the following ways: In the preregistration, the regression models did not include random slopes for target centrality (i.e., the distance between the location where the balloon landed and the center of the screen), neither within subject nor within cultural setting. Instead, the preregistration included random slopes for trial within subject. We decided to remove random slopes for trial but include them for target centrality because trial effects in the sense of learning across trials were unlikely in the absence of differential feedback. Furthermore, multiple studies with the same task since the registration found no trial effects [@prein2024tango; @prein2024variation]. On the other hand, we included random slopes for target centrality to be able to look at cross-cultural variation. We preregistered to run the cross-validation 1000 times but decided to scale down to 100 times because the procedure was computationally very intensive and the results very clear. The cognitive models were not mentioned in the preregistration because they were developed more recently [@prein2024variation].

## Open data and materials

All study materials <!--[masked for peer review] --> (https://ccp-odc.eva.mpg.de/tango-cc/), primary data, and analysis scripts are publicly available <!--[masked for peer review; see .zip file included--> (https://github.com/ccp-eva/gafo-cc-analysis/).

## Participants

```{r}
demtab <- data %>%
  separate(community, into = c("community", "country"), sep = " \\(")%>%
  mutate(country = str_remove(country, "\\("),
         country = str_remove(country, "\\)"))%>%
  distinct(subjid, .keep_all = T)%>%
  group_by(community, country, continent)%>%
  summarise(N = n_distinct(subjid), 
            m = sum(sex == "m", na.rm = T), 
            mean_age = mean(ageinyears),
            min_age = min(ageinyears), 
            max_age = max(ageinyears))%>%
  mutate_if(is.numeric, format, digits = 2, nsmall = 2)%>%
  mutate(age = paste(mean_age, " (", min_age, " - ", max_age, ")"))%>%
  select(-c(mean_age, min_age, max_age))%>%
  arrange(continent)
```

A total of `r sum(as.numeric(demtab$N))` children between `r round(min(data$ageinyears), 2)` and `r round(max(data$ageinyears), 2)` years of age provided data for the study. Children lived in `r n_distinct(data$community)` different communities, located in `r n_distinct(demtab$country)` different countries across five continents. Table \@ref(tab:tab1) gives the sample size per community together with basic demographic information and age. For some children, the exact birthday was unknown. In such cases, we set the birthday to the 30th of June of the year that would make them fall into the reported age category. We provide a detailed description of the sample characteristics, the age distributions, the study sites and recruitment strategies for each community in the Supplementary Material. Samples were convenience samples in all communities.

Data from children was only included in the study when they contributed at least four valid test trials. We also excluded the data from children when a developmental disorder was reported. In addition to the sample size reported above, 74 children participated in the study but did not contribute data. The main reasons for exclusion were: contribution of less than four valid test trials, technical failures, and missing or implausible demographic information (e.g., when the number of children living in the household was reported to be larger than the household itself or when the number of children reported to live in the household equaled the number of children younger than the child being tested). We did not exclude any participants for performance reasons. 

## Material and Procedure

The task was implemented as a browser-based interactive picture book using `HTML`, `CSS`, and `JavaScript`. Participants saw animated agents on a touch screen device, listened to pre-recorded audio instructions and responded by touching the screen. In all communities, a research assistant, fluent in the local language(s), guided the child through the introduction and advanced the study from trial to trial.

Figure \@ref(fig:fig1)B shows a screenshot from the task. The task was introduced verbally by the assistant as the balloon game in which the participant would play with other children to find a balloon. On each trial, participants saw an agent located in a window in the center of the screen. A balloon fell down from its starting position just below the agent. The agent's gaze followed the trajectory of the balloon. That is, the pupils and the iris were programmed to align with the center of the balloon. Once the balloon had landed on the ground, the child was instructed to locate it, that is, to touch the location on the screen where they thought the balloon was. On each trial, we recorded the exact x-coordinate of the participant's touch.

There were two types of training trials. In training 1 trials, the balloon fell down and landed in plain sight. Participants simply had to touch the visible balloon. In training 2 trials, the trajectory of the balloon was visible but it landed behind a small barrier (a hedge -- see Figure \@ref(fig:fig1)B). Thus, participants needed to touch the hedge where they saw the balloon land. Next came test trials. Here, the barrier moved up and covered the balloon's trajectory. That is, participants only saw the agent's eyes move, but not the balloon. They had to infer the location of the balloon based on the agent's gaze direction. During training 1, training 2 and the first test trial, children heard voice-overs commenting what happened on the screen. Critically, the agent was described as wanting to help the child and always looking at the balloon. These instructions were added to clarify the purpose of the task, establish a clear common ground, and minimize learning effects over trials. 

Children completed one training 1, two training 2 trials and 16 test trials. We excluded the first test trial from the analysis because of the voice-over. Thus, 15 test trials were used in the analysis below. Each child saw eight different agents (four male, four female; selected by local researchers or research assistants). The agent changed from trial to trial, with alternating genders. A coin toss before the first trial decided whether the first agent was male or female. The order in which agents were shown was randomized with the constraint that all agents had to be shown once until an agent was shown again. The color of the balloon also changed from trial to trial in a random order, also with the constraint that all colors appeared once before any one was repeated.

The location (x-coordinate) where the balloon landed was determined in the following way: The screen was divided in ten equally sized bins. On each trial, one of the bins was randomly selected and the exact x-coordinate was randomly chosen within that bin. Constraints were that the balloon landed in each bin once in the first ten trials and, for the remaining six test trials, it landed in a different bin on each trial. Thus, each bin appeared no more than twice.

All children were tested with a touchscreen device with a size between 11 and 13 inch equipped with a webcam. The data was stored locally. In addition to the behavioral data, we stored the webcam recording of the session for verification purposes. Community-specific adaptations were made by changing the visuals and the audio instructions (see Supplementary Material for details).

In addition to the gaze following task, caregivers responded to a short questionnaire about children’s access to screens and touchscreens (binary answer) as well as the number of people, children and children younger than the focal child living in the household (numeric; see Supplementary Material for details).

# Analysis

## Cross-cultural variation

We used Bayesian Regression models fit in `R` [@r] using the package `brms` [@burkner2017brms]. We used default priors built into `brms`. The dependent variable in all regression models was imprecision, that is, the absolute distance between the true location of the balloon (x-coordinate of its center) and the location where the participant touched the screen. We used a Log-normal distribution to model the data because the natural lower bound for imprecision is zero and the data was right skewed with a long tail. Numeric predictors that entered the models were scaled to have a mean of zero and a standard deviation of 1.

The first analysis was focused on cross-cultural variation. Fixed effects in the model were age and target centrality (distance of the balloon’s landing position from the center in pixel/SVG units). The latter term accounts for trial difficulty (see below). Furthermore, we included participant as a random effect, with a random slope for target centrality. To assess cross-cultural variation, we compared three models: a null model without cultural community as a predictor (`brms` notation: `imprecision ~ age + target_centrality + (target_centrality | participant)`), a model with cultural community as a random intercept (`imprecision ~ age + target_centrality + (target_centrality | participant) + (target_centrality | community)`), and a model with cultural community as a random intercept and an added random slope for age (`imprecision ~ age + target_centrality + (target_centrality | participant) + (age + target_centrality | community)`). Thus, the second model assumes that there is variation across cultures in average levels of precision and the third model assumes that there are additional cultural differences in the effect of age. 

As stated in the preregistration , comparing these models could be problematic. Participants are fully nested within a cultural setting. If there was an effect of cultural setting, we would expect participant random intercepts to cluster by cultural setting. This clustering would appear whether or not cultural community would be included in the model as a random effect or not -- the only difference would be if the participant random intercepts were estimated as a deviation from a grand intercept or a culture-specific one. Standard metrics such as `WAIC` or `LOO` would penalize the model with additional intercept for cultural community for having additional parameters that do not help to improve predictive accuracy.

To get around this problem, we used a cross-validation procedure [see e.g., @stengelin2023children]. For each cultural setting, we randomly sampled a data set that was 5/6 the size of the full data set (training data). Then, we fit the model to this training data and used the estimated model parameters to predict the remaining 1/6 of the data (testing data). We then compared the model predictions from the different models by computing the mean difference between the true and predicted imprecision, over all trials in the testing data set. This approach gets around the problem mentioned above because the model predicts a new data set for which the individual random intercepts are unknown. Clustering by culture could therefore only be predicted by a model that included culture as a predictor. We repeated the cross-validation procedure 100 times and counted which model performed best most often.

## Processing signatures

The processing signatures were derived from the model proposed by @prein2024variation. The model sees gaze following as form of social vector estimation. When following gaze, onlookers observe the location (and movement) of the pupil within the eye and estimate a vector emanating from the center of the eye through the pupil. The focus of attention is the location where the estimated vectors from both eyes hit a surface (Fig. \@ref(fig:fig12)). It is assumed that this estimation process is not perfect but has some uncertainty because the center of the eye is not directly observable. Individual differences are conceptualized as differences in the level of uncertainty. As a consequence, even though individuals are assumed to use the same general process, they might differ in their absolute levels of precision. 

The process model predicts a clear performance signature in the data: trials in which the agent looks further away from the center should result in lower levels of precision compared to trials in which the agent looks closer to the center. This prediction is best understood by considering a similar phenomenon: pointing a torch light to a flat surface. The width of the light beam represents each individual’s level of uncertainty in vector estimation. When the torch is directed straight down, the light beam is concentrated in a relatively small area. When the torch is rotated to the side, the light from one half of the cone must travel further than the light from the other half to reach the surface. As a consequence, the light is spread over a wider area (see Fig. \@ref(fig:fig12)).

In the following, we give a brief mathematical description of the model. The model inversely models the process generating touches on the screen based on observed eye movements and is defined as:

\begin{equation}
    P(\theta | x_c, \alpha_l, \alpha_r) \propto P(x_c | \alpha_l, \alpha_r, \theta)P(\theta)
\end{equation}

Here, $\theta$ represents an individual's level of precision in locating the focus of the agent's attention, $x_c$ represents the touched coordinate, and $\alpha_l$ and $\alpha_r$ correspond to the left and right pupil angles (each defined as the angle between a line connecting the center of the eye to the pupil and a line extended vertically downward from the center of the eye).

The basic assumption in this model is that participants touch on the screen location where they think the agent is looking. The true eye angles ($\alpha_l$ and $\alpha_r$) are not directly observable and are estimated with noise, yielding $\hat{\alpha_l}$ and $\hat{\alpha_r}$. 

Each touch $x_c$ implies a "matched pair" of estimated pupil angles $\hat{\alpha_l}$ and $\hat{\alpha_r}$, with the constraint that the lines extended along those two angles meet at the precise location of where the target is believed to be. As a consequence, we can rewrite the likelihood function of the model as:

\begin{equation}
P(x_c | \alpha_l, \alpha_r, \theta) \propto P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) P(x_c)
\end{equation}

$P(x_c)$ is a prior over potential target locations. Because the target was last visible in the screen and because the agent was located in the center, we assumed that participants have an a priori expectation that the target will land closer to the middle. We estimated the strength of this center bias (i.e., the standard deviation of a Normal distribution around the screen center) based on the data: $P(x_c) \sim \mathcal{N}(960, \sigma^p)$.

The primary inferential task for participants is therefore to estimate the pupil angles ($\hat{\alpha_l}$ and $\hat{\alpha_r}$), that is, to sample from the term $P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta)$. Here, we assumed that the pair of estimated pupil angles were sampled from a probability distribution which is the product of two Normal distributions of equal variance, $\sigma_v$, centered on the true pupil angles:

\begin{equation}
P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) \propto \phi(\hat{\alpha}_l ; \alpha_l, \sigma_v)\phi(\hat{\alpha}_r ; \alpha_r, \sigma_v),
\end{equation}

Thus, $\sigma_v$ determines the level of accuracy with which participants estimated the pupil angles, and it is thus the component of the model that defines $\theta$. Smaller values of $\sigma_v$ result in a narrow distribution around the pupil angle, making touches far away from the target less likely. Conversely, larger values for $\sigma_v$ lead to a wider distribution, making touches far away from the target more likely. To circle back to the analogy introduced above, $\sigma_v$ corresponds to the width of the light beam. Thus, the goal of the model was to estimate participant-specific values for $\sigma_v$: $\sigma_{v_i}$. For more details on how $\sigma_{v_i}$ was estimated, see the Supplementary Material.

As stated above, the key signature prediction of the model is that precision decreases when the balloon lands further away from the center. To test this prediction, we fit a model predicting imprecision by age and target centrality with random intercepts for participant and community and random slopes for target centrality within participant and age and target centrality within community (`imprecision ~ age + target_centrality + (target_centrality | participant) + (age + target_centrality | community)`). As stated above, the predictor target centrality captures the distance from the center so that a positive effect of target centrality (i.e., a positive estimate with a 95% CrI not overlapping with zero) would mean support for the processing signature. In addition, we visualized the data for each community and inspected the shape of the plot. 

A similar pattern, however, also arises when participants ignore the agent's gaze completely and instead follow simple heuristics. When participants always touch the center of the screen, regardless of where the agent is looking, trials in which the balloon lands further away from the center have a higher imprecision (resembling a v-shape). When participants randomly touch a location on the screen -- again ignoring the agent's gaze -- the maximum imprecision for trials in which the balloon lands in the center is half the width of the screen. When the balloon lands on one of the far ends of the screen, the maximum imprecision is a full screen width. Thus, across trials, the average imprecision is again higher when the balloon lands further away from the center, resulting in the same pattern as predicted by the model. 

Even though these alternatives are unlikely because they assume that participants ignore the agent's gaze, we nevertheless want to rule them out as processes generating the data. Thus, we implemented the gaze model along with the two alternative models in the probabilistic programming language `webppl` [@dippl]. The way the gaze model predicts the participants' behavior has been described above. The center bias model predicts a participant's touch by sampling from a Normal distribution around the center of the screen $P(x_c) \sim \mathcal{N}(960, 160)$ (960 is the x-coordinate of the center and 160 is the width of the balloon). The random guessing model predicts participant's touch by sampling from a uniform distribution over all possible locations that can be touched: $P(x_c) \sim \mathcal{U}(0, 1920)$. Information on the prior distributions for all model parameters can be found in the associated online repository. 

For each community, we compared models based on the marginal likelihood of the data for each model, which represents the likelihood of the data while averaging over the prior distribution on parameters. The pair-wise ratio of marginal likelihoods for two models is known as the Bayes Factor. Bayes Factors are a quantitative measure of the predictive quality of a model, taking into account the possible values of the model parameters weighted by their prior probabilities. The incorporation of the prior distribution over parameters in the averaging process implicitly considers model complexity: models with more parameters typically exhibit broader prior distributions over parameter values and broader prior distribution can attenuate the potential gains in predictive accuracy that a model with more parameters might otherwise achieve [@lee2014bayesian].

## Predictors of variation

The final analysis focused on whether we could predict performance in the task by methodological aspects of the study and aggregate measures of everyday social experience. For the ease of model fitting, we aggregated the data for each participant so that models predicted the average imprecision across trials. This approach is justified because the mean is nearly perfectly correlated with a model-based estimate of a participant's ability [$\sigma_v$ in the model above, see @prein2024variation] and because the predictor variables did not vary within child.

In the questionnaire, we asked about children’s exposure to screens as well as touchscreens. These two variables were largely redundant and so we included only one of them in the model. We chose the availability of a touchscreen as a predictor because the task itself was presented on a touchscreen and because there was more variation in this variable.

For household composition, we asked for the total number of people in the household, the number of children and the number of younger children. We standardized each predictor within each community before fitting the models. Thus, the interpretation of the coefficient is the gain in precision for living e.g., in a larger household relative to other children from the same community.

We compared a null model (`mean_imprecision ~ age + (age | community)`) to a model including access to touchscreens only as a fixed effect (`mean_imprecision ~ touchscreen + age + (age | culture)`), a model in which the effect of access to touchscreens was also allowed to vary by community (`mean_imprecision ~ touchscreen + age + (touchscreen + age | culture)`) and a model for each of the household-based predictors (e.g., `mean_imprecision ~ household_size + touchscreen + age + (age | culture)`). Models were fit in `brms` and compared based on the difference in expected log pointwise predictive density (`ELPD`) computed via the widely applicable information criterion (`WAIC`) and the standard error of that difference (SE). We inspected the estimates for fixed effects in the winning model along with their 95% CrI. 

For a community-level perspective, we correlated the proportion of children with access to touchscreens with an age-corrected performance average for each community. To obtain the latter, we extracted the random intercept estimates for community from the null model described above. Because the model also includes age as a fixed effect, these values reflect variation between communities once differences in age have been accounted for. 


# Results

```{r}
cv_cult <- readRDS("../saves/cross_validation_result.rds")
```

## Cross-cultural variation in development

There were marked differences in imprecision between communities (see Figure \@ref(fig:fig2)A). The cross-validation procedure found that a model assuming cross-cultural variation in average performance as well as developmental trajectories outperformed simpler models in `r round(mean(cv_cult$m3_beats_m1),2)*100`% (no variation in developmental trajectories) and `r round(mean(cv_cult$m3_beats_m2),2)*100`% (no variation between communities at all) of cases, respectively. Nevertheless, average differences in precision between communities were small compared to differences between individuals: communities did not form homogeneous clusters but largely overlapping distributions in that some individuals from communities with a lower average level of precision performed better compared to some individuals from a community with a very high average level of precision. Similarly, in all communities, some 4-year-olds outperformed children two years older than them (see Figure \@ref(fig:fig2)A). 

Next, we investigated developmental gains, that is, the extent to which children become more precise at estimating the target location with age. Across all 17 communities, we found a substantial increase in average levels of precision (decrease in imprecision) with age (fixed effect of age: $\beta$ = `r post_fix%>%filter(term == "ageinyears")%>%pull(Estimate)`, 95% Credible Interval (CrI) (`r post_fix%>%filter(term == "ageinyears")%>%pull(Q2.5)` — `r post_fix%>%filter(term == "ageinyears")%>%pull(Q97.5)`); range of community-level (random) effects: $\beta_{min}$ = `r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%tail(1)%>%pull(mean)`, 95% CrI (`r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%tail(1)%>%pull(lci)` — `r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%tail(1)%>%pull(uci)`) to $\beta_{max}$ = `r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%head(1)%>%pull(mean)`, 95% CrI (`r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%head(1)%>%pull(lci)` — `r post_agg%>%filter(type == "ageinyears")%>%arrange(mean)%>%head(1)%>%pull(uci)`)).


```{r fig2, include = T, fig.cap = "A) Developmental trajectory across and B) by community. The developmental trajectories are predicted based on a model of the data aggregated for each participant. C) Performance by target location on the screen across, and D) by community. Each bin covers 1/10th of the screen. Points show means, and error bars 95\\% confidence intervals for the data within that bin aggregated across participants. Transparent dots in A) and C) show aggregated data for each individual.", out.width="100%"}
knitr::include_graphics("../figures/pvis_pred.png")
```

## Processing signatures

```{r fig12, include = T, fig.align = "center", fig.cap = "Graphical illustration of the cognitive model. Individuals infer the target location of an agent’s attention by estimating a vector based on the position of the pupils within the eyes. This process is noisy, illustrated by the different vectors (transparent lines). Individuals differ in their level of precision (indicated by sigma). For a given level of precision, the further the target lands from the center of the screen, the less precise the model predicts individuals to be. Solid and transparent dots show simulated means and individual data points to illustrate the predicted effect of target position.", out.width="100%"}
knitr::include_graphics("../figures/fig1_3.png")
``` 

The key processing signature predicted by the cognitive model was that precision should decrease when the balloon landed further away from the center. This signature was clearly visible across all 17 communities (fixed effect for target centrality: $\beta$ = `r post_fix%>%filter(term == "targetcentralityx")%>%pull(Estimate)`, 95% CrI (`r post_fix%>%filter(term == "targetcentralityx")%>%pull(Q2.5)` — `r post_fix%>%filter(term == "targetcentralityx")%>%pull(Q97.5)`); range of community-level (random) effects: $\beta_{min}$ = `r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%tail(1)%>%pull(mean)`, 95% CrI (`r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%tail(1)%>%pull(lci)` — `r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%tail(1)%>%pull(uci)`) to $\beta_{max}$ = `r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%head(1)%>%pull(mean)`, 95% CrI (`r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%head(1)%>%pull(lci)` — `r post_agg%>%filter(type == "targetcentrality")%>%arrange(mean)%>%head(1)%>%pull(uci)`)). 

To rule out alternative explanations, we compared the focal gaze following model described above to the alternative center bias and random guessing models. We found overwhelming support for the gaze estimation model (min $BF_{10}$ > 100 000 for comparisons with both alternative models, see Supplementary Materials) in every community.

```{r}
pred_est <- readRDS("../saves/pred_est.rds")

pred_est_sc <- readRDS("../saves/pred_est_sc.rds")
```

## Predictors of variation

```{r tab2, include = T}
pred_model_comp <- readRDS("../saves/model_comp.rds")%>%
  mutate_if(is.numeric, format, digits = 2, nsmall = 2)%>%
  select(model, elpd_diff, se_diff, waic, se_waic, value)%>%
  mutate(model = recode(model, 
                        bm_pred_null = "null",
                        bm_pred_tc = "touchscreen",
                        bm_pred_tc_hh = "touchscreen + household",
                        bm_pred_tc_c = "touchscreen + children",
                        bm_pred_tc_yc = "touchscreen + younger children",
                        bm_pred_tc_rand = "touchscreen (by culture)"))

apa_table(pred_model_comp,
          col.names = linebreak(c("Model","diff\\textsubscript{WAIC}", "diff\\textsubscript{SE}", "WAIC", "SE\\textsubscript{WAIC}", "Weight")),
          caption = "Comparison of models predicting individual-level variation.",
          #align = paste0("m{", 1/(ncol(tba1) + 1), "\\linewidth}"),
          #longtable = TRUE,
          escape=TRUE)
```


The model comparison favored the model including touchscreen as a fixed effect (no variation between communities) with no additional predictors capturing aspects of household composition (see Table \@ref(tab:tab2)). Children with access to touchscreen devices had higher levels of precision ($\beta$ = `r pred_est%>%filter(term == "touchscreen")%>%pull(Estimate)`, 95% CrI = `r pred_est%>%filter(term == "touchscreen")%>%pull(Q2.5)` — `r pred_est%>%filter(term == "touchscreen")%>%pull(Q97.5)`). This effect was consistent across communities in that allowing the effect of access to touchscreens to vary across communities did not improve model fit. 

On a community level, average performance was lowest in communities in which touchscreen devices were the least frequent (community-level correlation between age-corrected imprecision and proportion of children with access to touchscreens: *r* = `r round(pttest$estimate,2)`, 95% CI = `r round(pttest$conf.int[1],2)` — `r round(pttest$conf.int[2],2)`).

Table \@ref(tab:predcomptable) shows that differences between models were small ($diff_{ELPD}$ < 1), suggesting that they were largely equivalent. For the sake of consistency, we also inspected the posterior estimates for household composition predictors, none of which had a 95% CrI excluding zero (household size: $\beta$ = `r pred_est_sc%>%filter(term == "household")%>%pull(Estimate)`, 95% CrI = `r pred_est_sc%>%filter(term == "household")%>%pull(Q2.5)` — `r pred_est_sc%>%filter(term == "household")%>%pull(Q97.5)`; no. of children: $\beta$ = `r pred_est_sc%>%filter(term == "children")%>%pull(Estimate)`, 95% CrI = `r pred_est_sc%>%filter(term == "children")%>%pull(Q2.5)` — `r pred_est_sc%>%filter(term == "children")%>%pull(Q97.5)`; younger children: $\beta$ = `r pred_est_sc%>%filter(term == "younger_children")%>%pull(Estimate)`, 95% CrI = `r pred_est_sc%>%filter(term == "younger_children")%>%pull(Q2.5)` — `r pred_est_sc%>%filter(term == "younger_children")%>%pull(Q97.5)`).

```{r}
cor_dat <- data%>%
  group_by(subjid, children)%>%
  summarise(click = mean(abs(clickdistfromtargetcenterx)))

ctest <- cor.test(cor_dat$children, cor_dat$click)
```

# Discussion

Following and understanding gaze is a foundational building block of human social cognition [@tomasello2007reliance; @scaife1975capacity; @langton2000eyes; @rossano2012gaze; @richardson2005looking; @sebanz2006joint]. A substantial body of work has explored the developmental onset of gaze following in early infancy and in a few selected cultural communities [@moore2008development; @tang2023slow; @gredeback2010development; @byers2021development]. The study reported here presents comparable data (i.e., collected via the same task with minimal superficial adjustments for each community) on the development of gaze following in young children from 17 communities from five continents. We found substantial variation between cultural communitites, both in average levels as well as the steepness of developmental trajectories. In that, however, individual-level variation greatly outweighed community-level variation. Despite community-level variation, we found evidence that the basic process of gaze following is the same across communities: we found key performance signatures in all communities, as predicted by a model conceptualizing gaze following as a form of social vector estimation. Individual differences in gaze following were related to children's exposure to touchscreens but not to aggregate measures of opportunities for social interaction (i.e., household composition). This study provides evidence for a putative universal in basic social cognition and presents a new approach to studying cognitive processing in light of cross-cultural and individual variation. 

The task we used has good individual-level measurement properties across cultures [@prein2024measuring]. This puts us in the position to contrast individual-level variability with community-level variation instead of dismissing the former as noise. The obvious pattern here was that cultural communitites did not form homogeneous clusters but greatly overlapping distributions. That is, variation in the average developmental trajectories was small compared to variation between individuals, both within communities and across them. Some individuals from the community with the highest average level of imprecision outperformed individuals from the community with the lowest average. Thus, the explanatory power of community-level variables might be limited. 

On the face of it, a community-level perspective on the results points to a urban vs. rural divide in the data. Importantly, our sample included urban communitites from the Global North and South so that geographic location and living conditions were only partly confounded (we did not collect data in rural communitites in the Global North). Case in point is Namibia, where we collected data in both types of communitites with results mirroring the overall pattern. In previous work, such differences were often attributed to specific community-level differences in everyday experience that come with urbanization [e.g., @amir2020developmental; @mavridis2020development]. However, correlations identified this way remain speculative because urban and rural communitites differ in a myriad of ways. Furthermore, this approach neglects within-community variation in everyday experience [@bohn2024understanding]. It is often chosen because the measures used are not suited to reliably quantify individual-level variation. Given the good measurement properties of our task and the individual-level assessment via the parental questionnaire, we were able to directly link aspects of experience and cognitive development, omitting the intermediate community level.

We investigated both methodological and household composition as potential predictors. Familiarity with the device used for data collection explained variation between communities. Children with more touchscreen experience were probably better at task handling and thus more likely to precisely touch the location they inferred the agent to look at. However, children from all communities were accurate when touching visible targets during training trials [see @prein2024measuring]. Importantly, the model comparison showed that this relation did not vary substantially across communities. The effect, however, did not explain all variation between individuals. For example, in Malatya (Türkiye) where 100% of children had access to touchscreens, there was still substantial variation between individuals. This strongly indicates that other factors likely contributed to individual differences. 

Social-interactional variables have been linked to the development of gaze following in previous work [@astor2020social; @movellan2002development; @senju2015early]. Consequently, we predicted that opportunities for social interaction -- approximated by household size and composition -- would be linked to performance in the task while accounting for absolute differences and the prevalence of touchscreens. This was not the case. Yet, this result does not provide strong evidence for the absence of a relation between social-interactional variables and the development of gaze following. Instead, we think it suggests that a more fine-grained measurement is necessary to identify the relevant aspects of social interaction.

Despite substantial variation, we found the expected processing signatures in the data from all communities. Alternative accounts for how this pattern might have arisen did not explain the data well. However, these alternative approaches did not present viable alternative theoretical accounts for how participants followed gaze and why they differed from one another because they assumed that participants ignored gaze altogether. An alternative account involving the use of gaze cues would be that participants do not differ in the precision with which they estimate the gaze vector but that they differ only in the precision with which they touch the inferred location on the screen. This alternative -- motor noise -- account, however, would not predict the effect of target centrality and the u-shaped relation between target location and precision because motor noise should lead to normally distributed touches around the inferred location. Thus, we take the results as support for the idea of a universal process that is well-approximated by the model. This cognitive process might be rooted in humans’ evolved cognitive architecture, which is later refined during ontogeny. The phylogenetic roots of these processes might possibly lie much deeper as primates from a wide range of species follow gaze [@rosati2009looking; @tomasello1998five; @itakura2004gaze; @kano2014cross]. Yet, similarities in overt behavior do not imply the same underlying cognitive processes. The present study defines clear performance signatures that can be explored in other species to test such evolutionary hypotheses.

An unexpected result was that imprecision was higher on the left compared to the right side of the screen. One candidate explanation for this pattern might be the dominance -- despite variation -- of right-handedness across cultures [@papadatou2020human]. As of now, this is mere speculation and future research should investigate the origins of this pattern in more detail.

The study has further limitations. The fact that performance in the task was correlated with exposure to touchscreens might have overshadowed other sources of variation. However, we think it is an important innovation that we were able to account for this effect. Most developmental cross-cultural studies do not even question the portability of their measurement instruments. Importantly, the key result that the processing signatures were evident in all communities, is immune to this finding. The potential that lies in the precise individual-level measurement that our task achieves was largely unexploited. As mentioned above, the questionnaire items only offered a very coarse picture into children's actual lived experiences. Future work could increase the resolution with which everyday experiences in children from diverse communities are recorded to compare the drivers behind social-cognitive development. Recent work in the field of language acquisition has shown how technological innovations allowed for direct recording of social interactions across communities which can be used to close this explanatory gap [@bergelson2023everyday; @donnelly2021longitudinal]. 

In sum, our work pioneers an approach that introduces computational modeling and precise individual-level measurement to the cross-cultural study of cognitive development. This approach allowed us to identify potential universals in the human cognitive architecture rather than just overt behavior. As such, it can serve as a blueprint for future research on a broad spectrum of cognitive abilities. Finally, the study provides a much-needed empirical foundation for theories on the nature of the human mind. Children from diverse communities deploy similar cognitive processes in interpreting gaze, pointing to a universal foundation of basic social cognition.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
