% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  man,floatsintext]{apa6}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{english}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
% Manuscript styling
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

% Table formatting
\usepackage{longtable}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\centering\begin{threeparttable}}
%   {\end{threeparttable}\end{landscape}}
\newenvironment{lltable}{\begin{landscape}\centering\begin{ThreePartTable}}{\end{ThreePartTable}\end{landscape}}

% Enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}

% \setlength{\parindent}{0.5in}
% \setlength{\parskip}{0pt plus 0pt minus 0pt}

% Overwrite redefinition of paragraph and subparagraph by the default LaTeX template
% See https://github.com/crsh/papaja/issues/292
\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries\itshape\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
  {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
  {-\z@\relax}%
  {\normalfont\normalsize\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother

\makeatletter
\usepackage{etoolbox}
\patchcmd{\maketitle}
  {\section{\normalfont\normalsize\abstractname}}
  {\section*{\normalfont\normalsize\abstractname}}
  {}{\typeout{Failed to patch abstract.}}
\patchcmd{\maketitle}
  {\section{\protect\normalfont{\@title}}}
  {\section*{\protect\normalfont{\@title}}}
  {}{\typeout{Failed to patch title.}}
\makeatother

\usepackage{xpatch}
\makeatletter
\xapptocmd\appendix
  {\xapptocmd\section
    {\addcontentsline{toc}{section}{\appendixname\ifoneappendix\else~\theappendix\fi\\: #1}}
    {}{\InnerPatchFailed}%
  }
{}{\PatchFailed}
\keywords{keywords\newline\indent Word count: X}
\usepackage{lineno}

\linenumbers
\usepackage{csquotes}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={A universal of human social cognition: Children from 17 communities process gaze in similar ways},
  pdfauthor={Manuel Bohn (ORCID: 0000-0001-6006-1348)1,2,*, Julia Prein (ORCID: 0000-0002-3154-6167)1,2,*, Agnes Ayikoru3, Florian M. Bednarski (ORCID: 0000-0003-4384-4791)4, Ardain Dzabatou5, Michael C. Frank (ORCID: 0000-0002-7551-4378)6, Annette M. E. Henderson (ORCID: 0000-0003-4384-4791)4, Joan Isabella3, Josefine Kalbitz2, Patricia Kanngiesser (ORCID:0000-0003-1068-3725)7, Dilara Keşşafoğlu (ORCID: 0000-0002-7356-0733)8, Bahar Köymen (ORCID: 0000-0001-5126-8240)9, Maira V. Manrique-Hernandez2, Shirley Magazi (ORCID: 0009-0006-0479-9800)10, Lizbeth Mújica-Manrique2, Julia Ohlendorf2, Damilola Olaoba2, Wesley R. Pieters (ORCID:0000-0002-6152-249X)10, Sarah Pope-Caldwell2, Katie Slocombe (ORCID: 0000-0002-7310-1887)11, Robert Z. Sparks (ORCID: 0000-0001-7545-0522)6, Jahnavi Sunderarajan2, Wilson Vieira2, Zhen Zhang (ORCID: 0000-0001-9300-0920)12, Yufei Zong (ORCID: 0009-0000-5012-0244)12, Roman Stengelin (ORCID: 0000-0003-2212-4613)2,10,+, \& Daniel B. M. Haun (ORCID: 0000-0002-3262-645X)2,+},
  pdflang={en-EN},
  pdfkeywords={keywords},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{A universal of human social cognition: Children from 17 communities process gaze in similar ways}
\author{Manuel Bohn (ORCID: 0000-0001-6006-1348)\textsuperscript{1,2,*}, Julia Prein (ORCID: 0000-0002-3154-6167)\textsuperscript{1,2,*}, Agnes Ayikoru\textsuperscript{3}, Florian M. Bednarski (ORCID: 0000-0003-4384-4791)\textsuperscript{4}, Ardain Dzabatou\textsuperscript{5}, Michael C. Frank (ORCID: 0000-0002-7551-4378)\textsuperscript{6}, Annette M. E. Henderson (ORCID: 0000-0003-4384-4791)\textsuperscript{4}, Joan Isabella\textsuperscript{3}, Josefine Kalbitz\textsuperscript{2}, Patricia Kanngiesser (ORCID:0000-0003-1068-3725)\textsuperscript{7}, Dilara Keşşafoğlu (ORCID: 0000-0002-7356-0733)\textsuperscript{8}, Bahar Köymen (ORCID: 0000-0001-5126-8240)\textsuperscript{9}, Maira V. Manrique-Hernandez\textsuperscript{2}, Shirley Magazi (ORCID: 0009-0006-0479-9800)\textsuperscript{10}, Lizbeth Mújica-Manrique\textsuperscript{2}, Julia Ohlendorf\textsuperscript{2}, Damilola Olaoba\textsuperscript{2}, Wesley R. Pieters (ORCID:0000-0002-6152-249X)\textsuperscript{10}, Sarah Pope-Caldwell\textsuperscript{2}, Katie Slocombe (ORCID: 0000-0002-7310-1887)\textsuperscript{11}, Robert Z. Sparks (ORCID: 0000-0001-7545-0522)\textsuperscript{6}, Jahnavi Sunderarajan\textsuperscript{2}, Wilson Vieira\textsuperscript{2}, Zhen Zhang (ORCID: 0000-0001-9300-0920)\textsuperscript{12}, Yufei Zong (ORCID: 0009-0000-5012-0244)\textsuperscript{12}, Roman Stengelin (ORCID: 0000-0003-2212-4613)\textsuperscript{2,10,+}, \& Daniel B. M. Haun (ORCID: 0000-0002-3262-645X)\textsuperscript{2,+}}
\date{}


\shorttitle{Gaze-following across 17 communities}

\authornote{

The authors would like to thank Luke Maurits for statistical advice. Manuel Bohn was supported by a Jacobs Foundation Research Fellowship (2022-1484-00). We are gratful to thank all children and caregivers for participating in the study. We thank the Max Planck Society for the Advancement fo Science.

The authors made the following contributions. Manuel Bohn (ORCID: 0000-0001-6006-1348): Conceptualization, Methodology, Formal Analysis, Writing - Original Draft Preparation, Writing - Review \& Editing; Julia Prein (ORCID: 0000-0002-3154-6167): Conceptualization, Methodology, Software, Investigation, Writing - Review \& Editing; Agnes Ayikoru: Investigation; Florian M. Bednarski (ORCID: 0000-0003-4384-4791): Investigation, Writing - Review \& Editing; Ardain Dzabatou: Investigation; Michael C. Frank (ORCID: 0000-0002-7551-4378): Investigation, Writing - Review \& Editing; Annette M. E. Henderson (ORCID: 0000-0003-4384-4791): Investigation, Writing - Review \& Editing; Joan Isabella: Investigation; Josefine Kalbitz: Investigation, Writing - Review \& Editing; Patricia Kanngiesser (ORCID:0000-0003-1068-3725): Investigation, Writing - Review \& Editing; Dilara Keşşafoğlu (ORCID: 0000-0002-7356-0733): Investigation, Writing - Review \& Editing; Bahar Köymen (ORCID: 0000-0001-5126-8240): Investigation, Writing - Review \& Editing; Maira V. Manrique-Hernandez: Investigation; Shirley Magazi (ORCID: 0009-0006-0479-9800): Investigation; Lizbeth Mújica-Manrique: Investigation, Writing - Review \& Editing; Julia Ohlendorf: Investigation; Damilola Olaoba: Investigation; Wesley R. Pieters (ORCID:0000-0002-6152-249X): Investigation, Writing - Review \& Editing; Sarah Pope-Caldwell: Investigation; Katie Slocombe (ORCID: 0000-0002-7310-1887): Investigation, Writing - Review \& Editing; Robert Z. Sparks (ORCID: 0000-0001-7545-0522): Investigation; Jahnavi Sunderarajan: Investigation; Wilson Vieira: Investigation; Zhen Zhang (ORCID: 0000-0001-9300-0920): Investigation, Writing - Review \& Editing; Yufei Zong (ORCID: 0009-0000-5012-0244): Investigation; Roman Stengelin (ORCID: 0000-0003-2212-4613): Conceptualization, Methodology, Investigation, Writing - Review \& Editing; Daniel B. M. Haun (ORCID: 0000-0002-3262-645X): Conceptualization, Funding acquisition, Writing - Review \& Editing.

Correspondence concerning this article should be addressed to Manuel Bohn (ORCID: 0000-0001-6006-1348), Universitätsallee 1, 21335 Lüneburg, Germany. E-mail: \href{mailto:manuel.bohn@leuphana.de}{\nolinkurl{manuel.bohn@leuphana.de}}

}

\affiliation{\vspace{0.5cm}\textsuperscript{1} Institute of Psychology in Education, Leuphana University Lüneburg\\\textsuperscript{2} Department of Comparative Cultural Psychology, Max Planck Institute for Evolutionary Anthropology\\\textsuperscript{3} Budongo Conservation Field Station\\\textsuperscript{4} School of Psychology, University of Auckland\\\textsuperscript{5} Université Marien Ngouabi\\\textsuperscript{6} Department of Psychology, Stanford University\\\textsuperscript{7} School of Psychology, University of Plymouth\\\textsuperscript{8} Department of Psychology, Koç University\\\textsuperscript{9} Division of Psychology, Communication, and Human Neuroscience, University of Manchester\\\textsuperscript{10} Department of Psychology and Social Work, University of Namibia\\\textsuperscript{11} Department of Psychology, University of York\\\textsuperscript{12} CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences\\\textsuperscript{*} joint first author\\\textsuperscript{+} joint last author}

\abstract{%
Theoretical accounts assume that key features of human social cognition are universal. Here we focus on gaze-following, the bedrock of social interactions and coordinated activities, to test this claim. In this comprehensive cross-cultural study spanning five continents and 17 distinct cultural communities, we examined the development of gaze-following in early childhood. We identified key processing signatures through a computational model that assumes that participants follow an individual's gaze by estimating a vector emanating from the eye-center through the pupil. Using a single reliable touchscreen-based task, we found these signatures in all communities, suggesting that children worldwide processed gaze in highly similar ways. Absolute differences in performance between groups are accounted for by a cross-culturally consistent relationship between children's exposure to touchscreens and their performance in the task. These results provide strong evidence for a universal process underlying a foundational socio-cognitive ability in humans that can be reliably inferred even in the presence of cultural variation in overt behavior.
}



\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Human socio-cognitive skills enable unique forms of communication and cooperation that provide a bedrock for cumulative culture and the formation of complex societies\textsuperscript{1--7}. The eyes are the proverbial ``window to the mind'' and eye gaze is essential for many social reasoning processes\textsuperscript{8--10}. Others' eye gaze is used to infer their focus of visual attention, which is a critical aspect of coordinated activities, including communication and cooperation\textsuperscript{11--16}.

The ability to follow gaze emerges early in development\textsuperscript{17--20}. The earliest signs of gaze-following have been found in infants as young as four months\textsuperscript{21,22}. Initially, infants rely more on head direction than actual gaze direction\textsuperscript{23,24}. Throughout the first two years of life, children refine their abilities: they interpret gaze in mentalistic terms, for example, they follow gaze to locations outside their own visual field by moving around barriers\textsuperscript{25}. Importantly, individual differences in children's gaze-following abilities predict later life outcomes, most notably communicative abilities\textsuperscript{26}. For example, gaze-following at 10 months predicts language scores at 18 months of age\textsuperscript{27}. Difficulties with gaze-following have been linked to developmental disorders, including Autism\textsuperscript{28--30}. This work highlights the importance of gaze-following as a foundational building block of human social interaction and its central place in theorizing.

A central assumption in the theoretical and empirical work discussed above is that, despite substantial variation in developmental contexts, gaze-following works and develops in the same way across human societies\textsuperscript{31}. This assumption -- despite being central to many developmental theories -- is currently not supported by evidence. On the contrary, cross-cultural studies have revealed substantial diversity in socio-cognitive development\textsuperscript{3,32--35}. One of the very few cross-cultural studies also found differences in the likelihood to follow gaze between communities\textsuperscript{36}.

One potential source for this paradox lies in the reliance on aggregated measures in cross-cultural studies. Absolute differences in mean performance across communities are interpreted as a signal of different underlying cognitive processes. Here, we resolve this paradox by instead focusing on processing signatures that can be investigated independently of absolute community-level differences. This allows us to directly evaluate the empirical foundation of claims about universal features of human social cognition. To this end, we conducted a pre-registered, large-scale, cross-cultural study on the development of gaze-following abilities to study potentially universal processing signatures.

The processing signatures were derived from a simple computational model that assumes that participants follow gaze by estimating a vector emanating from the eye center through the pupil\textsuperscript{37}. The key innovation of the model is that it explains how individuals may use the same cognitive process but still differ in their measured abilities. The process always involves estimating a vector but also involves a degree of uncertainty because the eye center is not directly observable. Individuals are assumed to differ in their level of uncertainty with which they estimate the vector which causes differences in their observable behavior. Importantly, the assumed process leaves a key signature in the data that is observable independent of the absolute level of performance. In the present study, we therefor focus on this signature instead of absolute levels of performance when evaluating the claim whether there is evidence for a universal cognitive mechanism underlying gaze-following.

The 1377 participants who took part in the study lived in 17 different communities across 14 countries and five continents (Fig. \ref{fig:fig1}A, Tab. \ref{tab:tab1}). These countries represent \textasciitilde46\% of the world's population. Communities covered a broad spectrum of geographical locations, social and political systems, languages, and subsistence styles (see Supplemental Materials). This diversity allowed us to overcome the common pitfall of cross-cultural studies that compare urban communities from the global north to rural communities from the global south\textsuperscript{38}.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/fig1_2} 

}

\caption{(A) Data collection sites. Points show the approximate geographical location of the data collection sites, coloring shows the sample sizes. (B) Screenshots from the task. Screenshots from the task. The upper scene depicts the start and the lower the choice phase in a test trial. Participants had to use the gaze of the agent to locate the balloon and touch the location on the hedge where they thought the balloon was. Agents, audio recordings and backgrounds were adapted to each cultural setting. (C) Drawings used as agents across cultural settings.}\label{fig:fig1}
\end{figure}

\begin{center}
\begin{ThreePartTable}

\begin{TableNotes}[para]
\normalsize{\textit{Note.} 1 Proportion of participants who have access to touchscreens according to parental questionnaire. 2 Local collaborators and piloting suggested that Nigerian English is suitable for Windhoek as well.}
\end{TableNotes}

\begin{longtable}{m{0.125\linewidth}m{0.125\linewidth}m{0.125\linewidth}m{0.125\linewidth}m{0.125\linewidth}m{0.125\linewidth}m{0.125\linewidth}}\noalign{\getlongtablewidth\global\LTcapwidth=\longtablewidth}
\caption{\label{tab:tab1}Participant demographics.}\\
\toprule
Continent & Country & Community & N(male) & Age (range) & Language & Touchscreen exposure1\\
\midrule
\endfirsthead
\caption*{\normalfont{Table \ref{tab:tab1} continued}}\\
\toprule
Continent & Country & Community & N(male) & Age (range) & Language & Touchscreen exposure1\\
\midrule
\endhead
Americas & Argentina & Buenos Aires & 105 (53) & 4.72 (3.00 - 6.96) & Spanish (Rioplatense) & 0.90\\
 & México & Ocuilan & 127 (63) & 4.96 (2.57 - 6.95) & Spanish (Mexican) & 0.77\\
 & USA & Stanford & 98 (54) & 4.99 (2.52 - 7.90) & English (American) & 0.98\\
Africa & Namibia & Hai||om & 60 (38) & 5.85 (2.74 - 8.34) & Hai||om & 0.05\\
 &  & Khwe & 59 (24) & 5.84 (3.38 - 8.63) & Khwedam & 0.19\\
 &  & Windhoek & 39 (17) & 5.69 (2.66 - 8.66) & English (Nigerian)2 & 0.95\\
 & Nigeria & Akure & 114 (54) & 5.07 (2.57 - 7.33) & English (Nigerian) & 0.91\\
 & Rep. Congo & BaYaka & 29 (13) & 7.80 (3.94 - 10.56) & BaYaka & 0.00\\
 &  & Bandongo & 30 (11) & 7.45 (3.50 - 10.95) & Lingala & 0.00\\
 & Uganda & Nyabyeya & 125 (62) & 5.94 (2.67 - 8.92) & Kiswahili & 0.34\\
 & Zambia & Chimfunshi & 22 (5) & 5.98 (2.88 - 8.00) & Bemba & 0.14\\
Europe & Germany & Leipzig & 100 (48) & 4.88 (2.53 - 6.95) & German & 0.89\\
 & UK & Plymouth & 70 (30) & 6.02 (2.38 - 8.94) & English (British) & 0.99\\
Asia & China & Beijing & 123 (62) & 5.47 (2.69 - 8.48) & Mandarin & 0.95\\
 & India & Pune & 148 (73) & 6.14 (3.06 - 8.83) & English (Indian) / Marathi & 0.93\\
 & Türkiye & Malatya & 85 (40) & 5.02 (2.75 - 7.12) & Turkish & 1.00\\
Oceania & New Zealand & Auckland & 43 (19) & 5.14 (2.81 - 8.75) & English (New Zealand) & 0.95\\
\bottomrule
\addlinespace
\insertTableNotes
\end{longtable}

\end{ThreePartTable}
\end{center}

We used an animated picture book tablet task in which participants had to locate a hidden object based on observing an agent's gaze. Children watched a balloon disappear behind a hedge. An agent followed the trajectory of the balloon with their eyes (Fig. \ref{fig:fig1}B). The key dependent variable was the (im)precision with which children located the agent's focus of attention, that is, the deviation between where the agent looked (where the balloon was) and the child's response. We adapted visuals and audio instructions specifically for each of the 17 communities. Previous work demonstrated excellent individual-level measurement properties for this task in a German sample\textsuperscript{39}.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{cross-cultural-variation-in-development}{%
\subsection{Cross-cultural variation in development}\label{cross-cultural-variation-in-development}}

As the first step, we investigated developmental improvements, that is, how children become more precise at estimating the target location with age. Across all 17 communities, we found a substantial increase in average levels of precision with age (fixed effect in Bayesian regression model\textsuperscript{40}: \(\beta\) = -0.30, 95\% Credible Interval (CrI) (-0.40 - -0.21); range of community-level (random) effects: \(\beta_{min}\) = -0.06, 95\% CrI (-0.18 - 0.05) to \(\beta_{max}\) = -0.59, 95\% CrI (-0.71 - -0.48)).

Nevertheless, there were also marked differences between communities (see Fig. \ref{fig:fig2}A). In a six-fold cross-validation procedure, we trained a regression model on a subset of the data (training data) to later predict the held-out data (testing data)\textsuperscript{41}. This procedure was repeated 100 times. We found that a model assuming cross-cultural variation in average performance as well as cross-cultural variation in developmental trajectories outperformed simpler models -- assuming no variation in the shape of developmental trajectories or no variation between settings at all -- in 98\% of cases (see Supplemental Material). There are numerous ways in which communities could be grouped that would fall in line with these absolute differences (e.g., market integration, average levels of education, or average household size). However, we deliberately want to avoid any such overly simplistic explanation based on group-level data. Instead, we think these results can be best understood in methodological terms in the form of exposure to touch-screen devices; a finding we discuss in more detail below. Importantly, average differences in precision between communities were small compared to differences between individuals: communities did not form homogeneous clusters but largely overlapping distributions in that some individuals from communities with a lower average level of precision performed better compared to some individuals from a setting with a very high average level of precision. Similarly, in all communities, some 4-year-olds outperformed children two years older than them (see Fig. \ref{fig:fig2}A). The lack of adequate individual-level measurement instruments in previous large-scale developmental cross-cultural studies made it impossible to contrast these perspectives. The substantial overlap between communities found here speaks against categorical differences in gaze-following and is suggestive of a universal underlying process. However, consistent developmental improvements and overlapping distributions alone cannot inform us about the cognitive processes children use when locating the agent's focus of attention.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/pvis_pred} 

}

\caption{A) Developmental trajectory across and B) by community. The developmental trajectories are predicted based on a model of the data aggregated for each participant. C) Performance by target location on the screen across, and D) by community. Each bin covers 1/10th of the screen. Points show means, and error bars 95\% confidence intervals for the data within that bin aggregated across participants. Transparent dots in A) and C) show aggregated data for each individual.}\label{fig:fig2}
\end{figure}

\hypertarget{universal-processing-signatures}{%
\subsection{Universal processing signatures}\label{universal-processing-signatures}}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../figures/fig1_3} 

}

\caption{Graphical illustration of the cognitive model. Individuals infer the target of an agent’s attention by estimating a vector based on the position of the pupils within the eyes. This process is noisy, illustrated by the different vectors (transparent lines). Individuals differ in their level of precision (indicated by sigma). For a given level of precision, the further the target lands from the centre of the screen, the less precise the model predicts individuals to be. Solid and transparent dots show simulated means and individual data points to illustrate the predicted effect of target position.}\label{fig:fig12}
\end{figure}

Recent computational work modeled gaze-following as social vector estimation\textsuperscript{37}. When following gaze, onlookers observer the location of the pupil within the eye and estimate a vector emanating from the center of the eye through the pupil. The focus of attention is the location where the estimated vectors from both eyes hit a surface (Fig. \ref{fig:fig12}). It is assumed that this estimation process has some uncertainty becasue the center of the eye is not directly observable and that individuals vary in their level of uncertainty. As a consequence, even though individuals use the same general process, they might differ in their absolute levels of precision. Crucially, this process model predicts a clear performance signature in our gaze-following task: Trials in which the agent looks further away from the center should result in lower levels of precision compared to trials in which the agent looks closer to the center. This prediction is best understood by considering a similar phenomenon: pointing a torch light to a flat surface. The width of the light beam represents each individual's level of uncertainty in vector estimation. When the torch is directed straight down, the light beam is concentrated in a relatively small area. When the torch is rotated to the side, the light from one half of the cone must travel further than the light from the other half to reach the surface. As a consequence, the light is spread over a wider area (see Fig. \ref{fig:fig12}).

This processing signature was clearly visible across all 17 communities. Precision decreased when the agent looked at locations further away from the center (fixed effect: \(\beta\) = 0.47, 95\% CrI (0.40 - 0.54); range of community-level effects: \(\beta_{min}\) = 0.58, 95\% CrI (0.51 - 0.66) to \(\beta_{max}\) = 0.16, 95\% CrI (-0.01 - 0.33)). Visualization of the data showed the predicted u-shaped pattern in all communities (see Fig. \ref{fig:fig2}B). These results indicate a universal cognitive process used by children in all communities. There are, however, alternative ways in which the u-shaped pattern might arise: if participants ignored the agent's gaze and instead always selected the middle of the screen (center bias) or randomly selected locations (random guessing), precision would also decrease when the balloon lands further away from the center. To rule out these alternative explanations, we directly compared three models that made different assumptions about how participants' responses were generated: the focal vector-based gaze estimation model described above, a center-bias model where participants always select the center, and a random guessing model where participants select random locations. For every community, we found overwhelming support for the gaze estimation model (min \(BF_{10}\) \textgreater{} 100 000 for comparisons with both alternative models). Taken together, children from all 17 communities processed gaze in similar ways.

\hypertarget{predictors-of-variation}{%
\subsection{Predictors of variation}\label{predictors-of-variation}}

Next, we looked at factors that could explain community- and individual-level variation. In addition to the gaze-following task, caregivers responded to a short questionnaire about children's access to screen-based technology and household composition. On an individual level, we found that children with access to touchscreen devices had higher levels of precision (\(\beta\) = -0.14, SE = 0.04, 95\% CrI = -0.21 - -0.07). This effect was consistent across communities in that allowing the effect of access to touchscreens to vary across communities did not improve model fit (see Supplemental Materials). On a community level, we also saw that average performance was lowest in communities in which touchscreen devices were the least frequent (community-level correlation between age-corrected imprecision and proportion of children with access to touchscreens: \emph{r} = -0.90, 95\% CI = -0.96 - -0.74). Thus, familiarity with the device used for data collection likely explains variation between communities. Children with more touchscreen experience were probably better at task handling and thus more likely to precisely touch the location they inferred the agent to look at.

However, there was substantial variation between individuals that could not be explained by differential exposures to touchscreens alone. For example, in Malatya (Türkyie) where 100\% of children had access to touchscreens there was still substantial variation between individuals (see Fig.\ref{fig:fig1}B). This strongly indicates that other factors likely contributed to individual differences. Social interaction has been highlighted as an important driver of social-cognitive development\textsuperscript{e.g., 31,42--45} and thus we hypothesized (and pre-registered) that more opportunities for social interaction -- approximated by living in larger households with more children -- would be associated with higher levels of precision. When predicting performance by relative opportunities for social interactions within a community -- while accounting for absolute differences and the prevalence of touchscreens -- we found no strong associations between any of the demographic indicators and performance (see Supplemental Material). Whilst household size was a useful proxy for regular social interaction opportunities, the measure does not directly measure the factors that previous work has suggested to be related to the development of gaze-following in younger children, such as attachment quality or the use of gaze in early communicative interactions\textsuperscript{46--48}.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Following and understanding gaze is a foundational building block of human social cognition\textsuperscript{11--16}. A substantial body of work has explored the developmental onset of gaze-following in a few selected cultural communities\textsuperscript{17--19,49}. The data reported here provides strong evidence that children from a large and diverse set of communities process others' gaze in similar ways. We found key performance signatures predicted by a model treating gaze-following as a form of social vector estimation across all 17 communities. With the focus on individual-level processing signatures, the study goes beyond previous studies on gaze-following -- focused on the onset of gaze-following in infancy\textsuperscript{36,50} -- as well as comprehensive cross-cultural studies that compared average developmental trajectories\textsuperscript{51--54}.

The cognitive processes underlying gaze-following might be rooted in humans' evolved cognitive architecture, which is -- presumably -- later refined during social interaction\textsuperscript{46--48}. The phylogenetic roots of these processes might possibly lie much deeper as primates from a wide range of species follow gaze\textsuperscript{55--58}. Yet, similarities in overt behavior do not imply the same underlying cognitive processes. The present study defines clear performance signatures that can be explored in other species to test such evolutionary hypotheses.

Our study combined precise individual-level cognitive measurement and individual-level assessment of experience (here: touchscreen exposure) in a large and diverse sample to directly investigate the impact of specific cultural experiences on developmental outcomes. Instead of establishing universality by maximizing the cultural distance between two or three tested communities\textsuperscript{59}, this large-scale cross-cultural approach treats children's cultural experience at scale, shedding light on the big ``middle ground'' of children's cultural experience\textsuperscript{38}.

The study has important limitations. The fact that performance in the task was correlated with exposure to touchscreens might have overshadowed other sources of variation. However, we think it is in an important innovation that we were able to account for this effect. Most developmental cross-cultural studies do not even question the portability of their measurement instruments. Importantly, the key result that the processing signatures were seen in all cultural settings, is immune to this finding. The potential that lies in the otherwise precise individual-level measurement that our task achieves is largely unexploited. The questionnaire items only offer a very coarse picture into children's actual lived experiences. Future work could increase the resolution with which everyday experiences in children from diverse communities are recorded to compare the drivers behind social-cognitive development as we observe it. Recent work in the field of language acquisition has shown how technological innovations allowed for direct recording of social interactions across communities which can be used to close this explanatory gap\textsuperscript{60,61}.

In sum, our work pioneers an approach that introduces computational modeling and precise individual-level measurement to the cross-cultural study of cognitive development. This approach allowed us to test for universals in the human cognitive architecture rather than just overt behavior. As such, it can serve as a blueprint for future research on a broad spectrum of cognitive abilities and offers a much-needed empirical foundation for theories on the nature of the human mind. Children from diverse cultures deploy similar cognitive processes in interpreting gaze, pointing to a universal foundation of basic social cognition, which is refined during development.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

A more detailed description of the materials and models can be found in the supplemental material. The experimental procedure and analysis plan were pre-registered (\url{https://osf.io/tdsvc}). We report on deviations from the pre-registered plan in the supplementary material. The task itself, including all the versions used in the study, can be accessed via the following website: \url{https://ccp-odc.eva.mpg.de/tango-cc/}. Data, model and analysis scripts can be found in an online repository (\url{https://github.com/ccp-eva/gafo-cc-analysis}).

\hypertarget{participants}{%
\subsection{Participants}\label{participants}}

A total of 1377 children between 2.38 and 10.95 provided data for the study. Children lived in 17 different communities, located in 14 different countries. Table \ref{tab:tab1} gives the sample size per community together with some basic demographic information. The recruitment strategy for each community is reported in the respective site descriptions. For some children, the exact birthday was unknown. In such cases, we set the birthday to the 30th of June of the year that would make them fall into the reported age category.

Data from children was only included in the study when they contributed at least four valid test trials. We also excluded the data from children with a diagnosed developmental disorder. In sum, in addition to the sample size reported above, 74 additional children participated in the study but did not contribute data. The main reasons for exclusion were: contribution of less than four valid test trials, technical failures, and missing or implausible demographic information (e.g., when the number of children living in the household was reported to be larger than the household itself or when the number of children reported to live in the household equaled the number of children younger than the child being tested). We did not exclude any participants for performance reasons. A detailed description of each data collection site and the way children were recruited can be found in the supplemental material.

\hypertarget{setup-and-procedure}{%
\subsection{Setup and Procedure}\label{setup-and-procedure}}

The task was implemented as a browser-based interactive picture book using \texttt{HTML} and \texttt{JavaScript}. Participants saw animated agents on a touch screen device, listened to pre-recorded audio instructions and responded by touching the screen. In all communities, a research assistant, fluent in the local language(s), guided the child through the task.

Figure \ref{fig:fig1}B shows a screenshot from the task. The task was introduced verbally by the assistant as the balloon game in which the participant would play with other children to find a balloon. On each trial, participants saw an agent located in a window in the center of the screen. A balloon fell down from its starting position just below the agent. The agent's gaze followed the trajectory of the balloon. That is, the pupils and the iris were programmed to align with the center of the balloon. Once the balloon had landed on the ground, the agent was instructed to locate it, that is, to touch the location on the screen where they thought the balloon was. On each trial, we recorded the exact x-coordinate of the participant's touch.

There were two types of familiarization trials. In fam1 trials, the balloon fell down and landed in plain sight. Participants simply had to touch the visible balloon. In fam2 trials, the trajectory of the balloon was visible but it landed behind a small barrier (a hedge - see Figure \ref{fig:fig1}B). Thus, participants needed to touch the hedge where they saw the balloon land. Next came test trials. Here, the barrier moved up and covered the balloon's trajectory. That is, participants only saw the agent's eyes move, but not the balloon. They had to infer the location of the balloon based on the agent's gaze direction. During fam1, fam2 and the first test trial, children heard voice overs commenting what happened on the screen. Critically, the agent was described as wanting to help the child and always looking at the balloon.

Children completed one fam1 trial, two fam2 trials and 16 test trials. We excluded the first test trial from the analysis because of the voice-over. Thus, 15 test trials were used in the analysis below.

Each child saw eight different agents, four male, four female. The agent changed from trial to trial, with alternating genders. A coin toss before the first trial decided whether the first agent was male or female. The order in which agents were shown was randomized with the constraint that all agents had to be shown once until an agent was shown again. The color of the balloon also changed from trial to trial in a random order, also with the constraint that all colors appeared once before any one was repeated.

The location (x-coordinate) where the balloon landed was determined in the following way: The screen was divided in ten equally sized bins. On each trial, one of the bins was randomly selected and the exact x-coordinate was randomly chosen within that bin. Constraints were that the balloon landed in each bin equally often and the same bin appeared no more than twice in a row.

All children were tested with a touchscreen device with a size between 11 and 13 inch equipped with a webcam. The data was either stored locally or sent to a server. In addition to the behavioral data, we stored the webcam recording of the session for verification purposes. Culture-specific adaptations were made by changing the visuals and the audio instructions (see supplementary material for details).

\hypertarget{analysis}{%
\subsection{Analysis}\label{analysis}}

We used Bayesian Regression models fit in \texttt{R}\textsuperscript{62} using the package \texttt{brms}\textsuperscript{63} for all analyses except the cognitive models. We used the default priors built in to \texttt{brms}. The dependent variable in all regression models was imprecision, that is, the absolute distance between the true location of the balloon (x-coordinate of its center) and the location where the participant touched the screen. We used a Log-normal distribution to model the data because the natural lower bound for imprecision is zero and the data was right skewed with a long tail. Numeric predictors that entered the models were scaled to have a mean of zero and a standard deviation of 1.

To analyse cross-cultural variation in performance, we used a cross-validation procedure\textsuperscript{see e.g., 41}. In the supplemental material we give a detailed justification of this approach. For each cultural setting, we randomly sampled a data set that was 5/6 the size of the full data set (training data). Then, we fit the model to this training data and used the estimated model parameters to predict the remaining 1/6 of the data (testing data). We then compared the model predictions from the different models by computing the mean difference between the true and predicted imprecision, over all trials in the testing data set. We repeated the cross-validation procedure 100 times and computed the percentage of cases in which one model outperformed the other. We compared three models: a null model assuming no systematic community-level variation, a model assuming variation between communities and a model assuming variation between communities and in developmental trajectories (see supplemental material for model equations).

To evaluate the processing signature that trials in which the balloon lands further away from the center lead to larger imprecision, we fit a model predicting imprecision by age and target centrality (distance of the landing position form the center in pixel) with random intercepts for participant and cultural setting and random slopes for target centrality within participant and cultural setting (\texttt{brms} notation: \texttt{age\ +\ target\_centrality\ +\ (target\_centrality\ \textbar{}\ participant)\ +\ (age\ +\ target\_centrality\ \textbar{}\ culture)}).

\hypertarget{cognitive-model}{%
\subsection{Cognitive model}\label{cognitive-model}}

The focal vector-based gaze estimation model has been described in detail in\textsuperscript{37}. In brief, it inversely models the process generating touches on the screen based on observed eye movements. Formally, the model is defined as:

\begin{equation}
    P(\theta | x_c, \alpha_l, \alpha_r) \propto P(x_c | \alpha_l, \alpha_r, \theta)P(\theta)
\end{equation}

Here, \(\theta\) represents an individual's cognitive ability to locate the focus of the agent's attention, \(x_c\) represents the touched coordinate, and \(\alpha_l\) and \(\alpha_r\) correspond to the left and right pupil angles (each defined as the angle between a line connecting the center of the eye to the pupil and a line extended vertically downward from the center of the eye).

The basic assumption in this model is that participants touch on the screen location where they think the agent is looking. The true eye angles (\(\alpha_l\) and \(\alpha_r\)) are not directly observable and are estimated with noise, yielding \(\hat{\alpha_l}\) and \(\hat{\alpha_r}\).

Each touch \(x_c\) implies a ``matched pair'' of estimated pupil angles \(\hat{\alpha_l}\) and \(\hat{\alpha_r}\), with the constraint that the lines extended along those two angles meet at the precise location of where the target is believed to be. As a consequence, we can rewrite the likelihood function of the model as:

\begin{equation}
P(x_c | \alpha_l, \alpha_r, \theta) \propto P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) P(x_c)
\end{equation}

\(P(x_c)\) is a prior over potential target locations. Because the target was last visible in the screen and because the agent was located in the center, we assumed that participants have an a priori expectation that the target will land close to the middle. We estimated the strength of this center bias (i.e., the standard deviation of a Normal distribution around the screen center) based on the data: \(P(x_c) \sim \mathcal{N}(960, \sigma^p)\).

The primary inferential task for participants is therefore to estimate the pupil angles (\(\hat{\alpha_l}\) and \(\hat{\alpha_r}\)), i.e., to sample from the term \(P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta)\). Here, we assumed that the pair of estimated pupil angles were sampled from a probability distribution which is the product of two Normal distributions of equal variance, \(\sigma_v\), centered on the true pupil angles:

\begin{equation}
P(\hat{\alpha_l}, \hat{\alpha_r} | \alpha_l, \alpha_r, \theta) \propto \phi(\hat{\alpha}_l ; \alpha_l, \sigma_v)\phi(\hat{\alpha}_r ; \alpha_r, \sigma_v),
\end{equation}

Here, \(\sigma_v\) determines the level of accuracy with which participants estimated the pupil angles, and it is thus the component of the model that defines \(\theta\). Smaller values of \(\sigma_v\) result in a narrow distribution around the pupil angle, making touches far away from the target less likely. Conversely, larger values for \(\sigma_v\) lead to a wider distribution, making touches far away from the target more likely. To circle back to the analogy introduced above, \(\sigma_v\) corresponds to the width of the light beam. Thus, the goal of the model was to estimate participant-specific values for \(\sigma_v\): \(\sigma_{v_i}\). For more details on how \(\sigma_{v_i}\) was estimated, see the supplementary material.

To summarize, the model assumes that participant's touches are generated by a process that relies on noisy estimates of the agent's gaze direction. The precision, with which the gaze direction is estimated, varies between participants and increases with development.

The two alternative models assume that participants ignore the agent's gaze completely, instead they are assumed to follow simple heuristics. According to the center bias model, they always try to touch in the center of the screen: \(P(x_c) \sim \mathcal{N}(960, 160)\). (960 is the x-coordinate of the center and 160 is the width of the balloon). According to the random guessing model, they randomly touch coordinates on the screen: \(P(x_c) \sim \mathcal{U}(0, 1920)\).

All models were run separately for each cultural setting. The code to run the models can be found in the associated online repository. We also refer to this source for information on the prior distributions for all model parameters.

The cognitive models were implemented in the probabilistic programming language \texttt{webppl}\textsuperscript{64}. We compared models based on the marginal likelihood of the data for each model, which represents the likelihood of the data while averaging over the prior distribution on parameters. The pair-wise ratio of marginal likelihoods for two models is known as the Bayes Factor. Bayes Factors are a quantitative measure of the predictive quality of a model, taking into account the possible values of the model parameters weighted by their prior probabilities. The incorporation of the prior distribution over parameters in the averaging process implicitly considers model complexity: models with more parameters typically exhibit broader prior distributions over parameter values and broader prior distribution can attenuate the potential gains in predictive accuracy that a model with more parameters might otherwise achieve\textsuperscript{65}.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\leavevmode\vadjust pre{\hypertarget{ref-tomasello2020adaptive}{}}%
\CSLLeftMargin{1. }%
\CSLRightInline{Tomasello, M. The adaptive origins of uniquely human sociality. \emph{Philosophical Transactions of the Royal Society B} \textbf{375}, 20190493 (2020).}

\leavevmode\vadjust pre{\hypertarget{ref-laland2021understanding}{}}%
\CSLLeftMargin{2. }%
\CSLRightInline{Laland, K. \& Seed, A. Understanding human cognitive uniqueness. \emph{Annual Review of Psychology} \textbf{72}, 689--716 (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-wellman2014making}{}}%
\CSLLeftMargin{3. }%
\CSLRightInline{Wellman, H. M. \emph{Making minds: How theory of mind develops}. (Oxford University Press, 2014).}

\leavevmode\vadjust pre{\hypertarget{ref-henrich2016secret}{}}%
\CSLLeftMargin{4. }%
\CSLRightInline{Henrich, J. \emph{The secret of our success: How culture is driving human evolution, domesticating our species, and making us smarter}. (princeton University press, 2016).}

\leavevmode\vadjust pre{\hypertarget{ref-tomasello2003makes}{}}%
\CSLLeftMargin{5. }%
\CSLRightInline{Tomasello, M. \& Rakoczy, H. What makes human cognition unique? From individual to shared to collective intentionality. \emph{Mind \& language} \textbf{18}, 121--147 (2003).}

\leavevmode\vadjust pre{\hypertarget{ref-legare2019development}{}}%
\CSLLeftMargin{6. }%
\CSLRightInline{Legare, C. H. The development of cumulative cultural learning. \emph{Annual Review of Developmental Psychology} \textbf{1}, 119--147 (2019).}

\leavevmode\vadjust pre{\hypertarget{ref-heyes2018cognitive}{}}%
\CSLLeftMargin{7. }%
\CSLRightInline{Heyes, C. \emph{Cognitive gadgets}. (Harvard University Press, 2018).}

\leavevmode\vadjust pre{\hypertarget{ref-shepherd2010following}{}}%
\CSLLeftMargin{8. }%
\CSLRightInline{Shepherd, S. V. Following gaze: Gaze-following behavior as a window into social cognition. \emph{Frontiers in integrative neuroscience} \textbf{4}, 5 (2010).}

\leavevmode\vadjust pre{\hypertarget{ref-doherty2006development}{}}%
\CSLLeftMargin{9. }%
\CSLRightInline{Doherty, M. J. The development of mentalistic gaze understanding. \emph{Infant and Child Development} \textbf{15}, 179--186 (2006).}

\leavevmode\vadjust pre{\hypertarget{ref-emery2000eyes}{}}%
\CSLLeftMargin{10. }%
\CSLRightInline{Emery, N. J. The eyes have it: The neuroethology, function and evolution of social gaze. \emph{Neuroscience \& biobehavioral reviews} \textbf{24}, 581--604 (2000).}

\leavevmode\vadjust pre{\hypertarget{ref-tomasello2007reliance}{}}%
\CSLLeftMargin{11. }%
\CSLRightInline{Tomasello, M., Hare, B., Lehmann, H. \& Call, J. Reliance on head versus eyes in the gaze following of great apes and human infants: The cooperative eye hypothesis. \emph{Journal of Human Evolution} \textbf{52}, 314--320 (2007).}

\leavevmode\vadjust pre{\hypertarget{ref-scaife1975capacity}{}}%
\CSLLeftMargin{12. }%
\CSLRightInline{Scaife, M. \& Bruner, J. S. The capacity for joint visual attention in the infant. \emph{Nature} \textbf{253}, 265--266 (1975).}

\leavevmode\vadjust pre{\hypertarget{ref-langton2000eyes}{}}%
\CSLLeftMargin{13. }%
\CSLRightInline{Langton, S. R., Watt, R. J. \& Bruce, V. Do the eyes have it? Cues to the direction of social attention. \emph{Trends in cognitive sciences} \textbf{4}, 50--59 (2000).}

\leavevmode\vadjust pre{\hypertarget{ref-rossano2012gaze}{}}%
\CSLLeftMargin{14. }%
\CSLRightInline{Rossano, F. Gaze in conversation. \emph{The handbook of conversation analysis} 308--329 (2012).}

\leavevmode\vadjust pre{\hypertarget{ref-richardson2005looking}{}}%
\CSLLeftMargin{15. }%
\CSLRightInline{Richardson, D. C. \& Dale, R. Looking to understand: The coupling between speakers' and listeners' eye movements and its relationship to discourse comprehension. \emph{Cognitive science} \textbf{29}, 1045--1060 (2005).}

\leavevmode\vadjust pre{\hypertarget{ref-sebanz2006joint}{}}%
\CSLLeftMargin{16. }%
\CSLRightInline{Sebanz, N., Bekkering, H. \& Knoblich, G. Joint action: Bodies and minds moving together. \emph{Trends in cognitive sciences} \textbf{10}, 70--76 (2006).}

\leavevmode\vadjust pre{\hypertarget{ref-tang2023slow}{}}%
\CSLLeftMargin{17. }%
\CSLRightInline{Tang, Y., Gonzalez, M. R. \& Deák, G. O. The slow emergence of gaze-and point-following: A longitudinal study of infants from 4 to 12 months. \emph{Developmental Science} e13457 (2023).}

\leavevmode\vadjust pre{\hypertarget{ref-gredeback2010development}{}}%
\CSLLeftMargin{18. }%
\CSLRightInline{Gredebäck, G., Fikke, L. \& Melinder, A. The development of joint visual attention: A longitudinal study of gaze following during interactions with mothers and strangers. \emph{Developmental science} \textbf{13}, 839--848 (2010).}

\leavevmode\vadjust pre{\hypertarget{ref-byers2021development}{}}%
\CSLLeftMargin{19. }%
\CSLRightInline{Byers-Heinlein, K. \emph{et al.} The development of gaze following in monolingual and bilingual infants: A multi-laboratory study. \emph{Infancy} \textbf{26}, 4--38 (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-del2019developmental}{}}%
\CSLLeftMargin{20. }%
\CSLRightInline{Del Bianco, T., Falck-Ytter, T., Thorup, E. \& Gredebäck, G. The developmental origins of gaze-following in human infants. \emph{Infancy} \textbf{24}, 433--454 (2019).}

\leavevmode\vadjust pre{\hypertarget{ref-astor2021gaze}{}}%
\CSLLeftMargin{21. }%
\CSLRightInline{Astor, K., Thiele, M. \& Gredebäck, G. Gaze following emergence relies on both perceptual cues and social awareness. \emph{Cognitive Development} \textbf{60}, 101121 (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-d1997demonstration}{}}%
\CSLLeftMargin{22. }%
\CSLRightInline{D'Entremont, B., Hains, S. M. \& Muir, D. W. A demonstration of gaze following in 3-to 6-month-olds. \emph{Infant Behavior and Development} \textbf{20}, 569--572 (1997).}

\leavevmode\vadjust pre{\hypertarget{ref-michel2021effects}{}}%
\CSLLeftMargin{23. }%
\CSLRightInline{Michel, C., Kayhan, E., Pauen, S. \& Hoehl, S. Effects of reinforcement learning on gaze following of gaze and head direction in early infancy: An interactive eye-tracking study. \emph{Child Development} \textbf{92}, e364--e382 (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-lempers1977development}{}}%
\CSLLeftMargin{24. }%
\CSLRightInline{Lempers, J. D., Flavell, E. R. \& Flavell, J. H. The development in very young children of tacit knowledge concerning visual perception. \emph{Genetic Psychology Monographs} \textbf{95}, 3--53 (1977).}

\leavevmode\vadjust pre{\hypertarget{ref-moll200412}{}}%
\CSLLeftMargin{25. }%
\CSLRightInline{Moll, H. \& Tomasello, M. 12-and 18-month-old infants follow gaze to spaces behind barriers. \emph{Developmental science} \textbf{7}, F1--F9 (2004).}

\leavevmode\vadjust pre{\hypertarget{ref-carpenter1998social}{}}%
\CSLLeftMargin{26. }%
\CSLRightInline{Carpenter, M., Nagell, K., Tomasello, M., Butterworth, G. \& Moore, C. Social cognition, joint attention, and communicative competence from 9 to 15 months of age. \emph{Monographs of the society for research in child development} i--174 (1998).}

\leavevmode\vadjust pre{\hypertarget{ref-brooks2005development}{}}%
\CSLLeftMargin{27. }%
\CSLRightInline{Brooks, R. \& Meltzoff, A. N. The development of gaze following and its relation to language. \emph{Developmental science} \textbf{8}, 535--543 (2005).}

\leavevmode\vadjust pre{\hypertarget{ref-itier2009neural}{}}%
\CSLLeftMargin{28. }%
\CSLRightInline{Itier, R. J. \& Batty, M. Neural bases of eye and gaze processing: The core of social cognition. \emph{Neuroscience \& Biobehavioral Reviews} \textbf{33}, 843--863 (2009).}

\leavevmode\vadjust pre{\hypertarget{ref-thorup2016altered}{}}%
\CSLLeftMargin{29. }%
\CSLRightInline{Thorup, E. \emph{et al.} Altered gaze following during live interaction in infants at risk for autism: An eye tracking study. \emph{Molecular autism} \textbf{7}, 1--10 (2016).}

\leavevmode\vadjust pre{\hypertarget{ref-thorup2018reduced}{}}%
\CSLLeftMargin{30. }%
\CSLRightInline{Thorup, E. \emph{et al.} Reduced alternating gaze during social interaction in infancy is associated with elevated symptoms of autism in toddlerhood. \emph{Journal of Abnormal Child Psychology} \textbf{46}, 1547--1561 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-tomasello2019becoming}{}}%
\CSLLeftMargin{31. }%
\CSLRightInline{Tomasello, M. \emph{Becoming human: A theory of ontogeny}. (Harvard University Press, 2019).}

\leavevmode\vadjust pre{\hypertarget{ref-miller2018contributions}{}}%
\CSLLeftMargin{32. }%
\CSLRightInline{Miller, J. G., Wice, M. \& Goyal, N. Contributions and challenges of cultural research on the development of social cognition. \emph{Developmental Review} \textbf{50}, 65--76 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-mayer2013synchrony}{}}%
\CSLLeftMargin{33. }%
\CSLRightInline{Mayer, A. \& Träuble, B. E. Synchrony in the onset of mental state understanding across cultures? A study among children in samoa. \emph{International Journal of Behavioral Development} \textbf{37}, 21--28 (2013).}

\leavevmode\vadjust pre{\hypertarget{ref-dixson2018scaling}{}}%
\CSLLeftMargin{34. }%
\CSLRightInline{Dixson, H. G., Komugabe-Dixson, A. F., Dixson, B. J. \& Low, J. Scaling theory of mind in a small-scale society: A case study from vanuatu. \emph{Child Development} \textbf{89}, 2157--2175 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-taumoepeau2019cross}{}}%
\CSLLeftMargin{35. }%
\CSLRightInline{Taumoepeau, M., Sadeghi, S. \& Nobilo, A. Cross-cultural differences in children's theory of mind in iran and new zealand: The role of caregiver mental state talk. \emph{Cognitive Development} \textbf{51}, 32--45 (2019).}

\leavevmode\vadjust pre{\hypertarget{ref-callaghan2011early}{}}%
\CSLLeftMargin{36. }%
\CSLRightInline{Callaghan, T. \emph{et al.} Early social cognition in three cultural contexts. \emph{Monographs of the society for research in child development} i--142 (2011).}

\leavevmode\vadjust pre{\hypertarget{ref-prein2023variation}{}}%
\CSLLeftMargin{37. }%
\CSLRightInline{Prein, J. C., Maurits, L., Werwach, A., Haun, D. B. M. \& Bohn, M. Variation in gaze understanding across the life span: {A} process-level perspective. \emph{{PsyArXiv}} (2023). doi:\href{https://doi.org/10.31234/osf.io/dy73a}{10.31234/osf.io/dy73a}}

\leavevmode\vadjust pre{\hypertarget{ref-barrett2020towards}{}}%
\CSLLeftMargin{38. }%
\CSLRightInline{Barrett, H. C. Towards a cognitive science of the human: Cross-cultural approaches and their urgency. \emph{Trends in Cognitive Sciences} \textbf{24}, 620--638 (2020).}

\leavevmode\vadjust pre{\hypertarget{ref-prein2023tango}{}}%
\CSLLeftMargin{39. }%
\CSLRightInline{Prein, J. C., Kalinke, S., Haun, D. B. \& Bohn, M. TANGO: A reliable, open-source, browser-based task to assess individual differences in gaze understanding in 3 to 5-year-old children and adults. \emph{Behavior Research Methods} 1--17 (2023).}

\leavevmode\vadjust pre{\hypertarget{ref-burkner2019bayesian}{}}%
\CSLLeftMargin{40. }%
\CSLRightInline{Bürkner, P.-C. Bayesian item response modeling in r with brms and stan. \emph{arXiv preprint arXiv:1905.09501} (2019).}

\leavevmode\vadjust pre{\hypertarget{ref-stengelin2023children}{}}%
\CSLLeftMargin{41. }%
\CSLRightInline{Stengelin, R., Ball, R., Maurits, L., Kanngiesser, P. \& Haun, D. B. Children over-imitate adults and peers more than puppets. \emph{Developmental Science} \textbf{26}, e13303 (2023).}

\leavevmode\vadjust pre{\hypertarget{ref-carpendale2020makes}{}}%
\CSLLeftMargin{42. }%
\CSLRightInline{Carpendale, J. \& Lewis, C. \emph{What makes us human: How minds develop through social interactions}. (Routledge, 2020).}

\leavevmode\vadjust pre{\hypertarget{ref-barresi1996intentional}{}}%
\CSLLeftMargin{43. }%
\CSLRightInline{Barresi, J. \& Moore, C. Intentional relations and social understanding. \emph{Behavioral and brain sciences} \textbf{19}, 107--122 (1996).}

\leavevmode\vadjust pre{\hypertarget{ref-perner1994theory}{}}%
\CSLLeftMargin{44. }%
\CSLRightInline{Perner, J., Ruffman, T. \& Leekam, S. R. Theory of mind is contagious: You catch it from your sibs. \emph{Child Development} \textbf{65}, 1228--1238 (1994).}

\leavevmode\vadjust pre{\hypertarget{ref-rakoczy2022foundations}{}}%
\CSLLeftMargin{45. }%
\CSLRightInline{Rakoczy, H. Foundations of theory of mind and its development in early childhood. \emph{Nature Reviews Psychology} \textbf{1}, 223--235 (2022).}

\leavevmode\vadjust pre{\hypertarget{ref-astor2020social}{}}%
\CSLLeftMargin{46. }%
\CSLRightInline{Astor, K. \emph{et al.} Social and emotional contexts predict the development of gaze following in early infancy. \emph{Royal Society open science} \textbf{7}, 201178 (2020).}

\leavevmode\vadjust pre{\hypertarget{ref-movellan2002development}{}}%
\CSLLeftMargin{47. }%
\CSLRightInline{Movellan, J. R. \& Watson, J. S. The development of gaze following as a bayesian systems identification problem. in \emph{Proceedings 2nd international conference on development and learning. ICDL 2002} 34--40 (IEEE, 2002).}

\leavevmode\vadjust pre{\hypertarget{ref-senju2015early}{}}%
\CSLLeftMargin{48. }%
\CSLRightInline{Senju, A. \emph{et al.} Early social experience affects the development of eye gaze processing. \emph{Current Biology} \textbf{25}, 3086--3091 (2015).}

\leavevmode\vadjust pre{\hypertarget{ref-moore2008development}{}}%
\CSLLeftMargin{49. }%
\CSLRightInline{Moore, C. The development of gaze following. \emph{Child Development Perspectives} \textbf{2}, 66--70 (2008).}

\leavevmode\vadjust pre{\hypertarget{ref-hernik2019infant}{}}%
\CSLLeftMargin{50. }%
\CSLRightInline{Hernik, M. \& Broesch, T. Infant gaze following depends on communicative signals: An eye-tracking study of 5-to 7-month-olds in vanuatu. \emph{Developmental science} \textbf{22}, e12779 (2019).}

\leavevmode\vadjust pre{\hypertarget{ref-house2020universal}{}}%
\CSLLeftMargin{51. }%
\CSLRightInline{House, B. R. \emph{et al.} Universal norm psychology leads to societal diversity in prosocial behaviour and development. \emph{Nature Human Behaviour} \textbf{4}, 36--44 (2020).}

\leavevmode\vadjust pre{\hypertarget{ref-van2018development}{}}%
\CSLLeftMargin{52. }%
\CSLRightInline{Van Leeuwen, E. J. \emph{et al.} The development of human social learning across seven societies. \emph{Nature Communications} \textbf{9}, 2076 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-blake2015ontogeny}{}}%
\CSLLeftMargin{53. }%
\CSLRightInline{Blake, P. R. \emph{et al.} The ontogeny of fairness in seven societies. \emph{Nature} \textbf{528}, 258--261 (2015).}

\leavevmode\vadjust pre{\hypertarget{ref-kanngiesser2022children}{}}%
\CSLLeftMargin{54. }%
\CSLRightInline{Kanngiesser, P. \emph{et al.} Children across societies enforce conventional norms but in culturally variable ways. \emph{Proceedings of the National Academy of Sciences} \textbf{119}, e2112521118 (2022).}

\leavevmode\vadjust pre{\hypertarget{ref-rosati2009looking}{}}%
\CSLLeftMargin{55. }%
\CSLRightInline{Rosati, A. G. \& Hare, B. Looking past the model species: Diversity in gaze-following skills across primates. \emph{Current opinion in neurobiology} \textbf{19}, 45--51 (2009).}

\leavevmode\vadjust pre{\hypertarget{ref-tomasello1998five}{}}%
\CSLLeftMargin{56. }%
\CSLRightInline{Tomasello, M., Call, J. \& Hare, B. Five primate species follow the visual gaze of conspecifics. \emph{Animal behaviour} \textbf{55}, 1063--1069 (1998).}

\leavevmode\vadjust pre{\hypertarget{ref-itakura2004gaze}{}}%
\CSLLeftMargin{57. }%
\CSLRightInline{Itakura, S. Gaze-following and joint visual attention in nonhuman animals. \emph{Japanese Psychological Research} \textbf{46}, 216--226 (2004).}

\leavevmode\vadjust pre{\hypertarget{ref-kano2014cross}{}}%
\CSLLeftMargin{58. }%
\CSLRightInline{Kano, F. \& Call, J. Cross-species variation in gaze following and conspecific preference among great apes, human infants and adults. \emph{Animal Behaviour} \textbf{91}, 137--150 (2014).}

\leavevmode\vadjust pre{\hypertarget{ref-norenzayan2005psychological}{}}%
\CSLLeftMargin{59. }%
\CSLRightInline{Norenzayan, A. \& Heine, S. J. Psychological universals: What are they and how can we know? \emph{Psychological Bulletin} \textbf{131}, 763 (2005).}

\leavevmode\vadjust pre{\hypertarget{ref-bergelson2023everyday}{}}%
\CSLLeftMargin{60. }%
\CSLRightInline{Bergelson, E. \emph{et al.} Everyday language input and production in 1,001 children from six continents. \emph{Proceedings of the National Academy of Sciences} \textbf{120}, e2300671120 (2023).}

\leavevmode\vadjust pre{\hypertarget{ref-donnelly2021longitudinal}{}}%
\CSLLeftMargin{61. }%
\CSLRightInline{Donnelly, S. \& Kidd, E. The longitudinal relationship between conversational turn-taking and vocabulary growth in early language development. \emph{Child Development} \textbf{92}, 609--625 (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-r}{}}%
\CSLLeftMargin{62. }%
\CSLRightInline{R Core Team. \emph{\href{https://www.R-project.org/}{R: A language and environment for statistical computing}}. (R Foundation for Statistical Computing, 2023).}

\leavevmode\vadjust pre{\hypertarget{ref-burkner2017brms}{}}%
\CSLLeftMargin{63. }%
\CSLRightInline{Bürkner, P.-C. Brms: An r package for bayesian multilevel models using stan. \emph{Journal of Statistical Software} \textbf{80}, 1--28 (2017).}

\leavevmode\vadjust pre{\hypertarget{ref-dippl}{}}%
\CSLLeftMargin{64. }%
\CSLRightInline{Goodman, N. D. \& Stuhlmüller, A. {The design and implementation of probabilistic programming languages}. (2014).}

\leavevmode\vadjust pre{\hypertarget{ref-lee2014bayesian}{}}%
\CSLLeftMargin{65. }%
\CSLRightInline{Lee, M. D. \& Wagenmakers, E.-J. \emph{Bayesian cognitive modeling: A practical course}. (Cambridge University Press, 2014).}

\end{CSLReferences}


\end{document}
